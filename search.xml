<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RocketMQ实战（三）]]></title>
    <url>%2Fmq%2Fmq-rocketmq-3%2F</url>
    <content type="text"><![CDATA[关于多Master多Slave的说明 由于在之前的博客中已经搭建了双Master，其实多Master多Slave大同小异，因此这里并不会一步步的演示搭建多Master多Slave，而是从思路上，分析下重点应该注意的配置项。 这四台机器，对外是一个统一的整体，是一个rocketmq cluster，因此需要brokerClusterName保持统一 123机器是121的从，124机器是122的从，如何在配置中体现？ 主和从的brokerName需要保持一致，另外brokerId标示了谁是主，谁是从（brokerId=0的就是主，大于0的就是从） 注意namesrvAddr的地址是4台NameServer 配置项中brokerRole需要指明 ASYNC_MASTER（异步复制Master） or SYNC_MASTER（同步双写Master） or SLAVE（从） 和以前的多Master启动方式一致，先启动4台Namesrv，然后用指定配置文件的方式启动Master/Slave即可 多Master多Slave的好处在于，即便集群中某个broker挂了，也可以继续消费，保证了实时性的高可用，但是并不是说某个master挂了，slave就可以升级master，开源版本的rocketmq是不可以的。也就是说，在这种情况下，slave只能提供读的功能，将失去消息负载的能力。 Queue in Topic对于RocketMQ而言，Topic只是一个逻辑上的概念，真正的消息存储其实是在Topic中的Queue中。想一想，为什么RocketMQ要这要设计呢？其实是为了消息的顺序消费，后文中将为大家介绍。 初步认识RocketMQ的核心模块 rocketmq-broker：接受生产者发来的消息并存储（通过调用rocketmq-store），消费者从这里取得消息。 rocketmq-client：提供发送、接受消息的客户端API。 rocketmq-namesrv：NameServer，类似于Zookeeper，这里保存着消息的TopicName，队列等运行时的元信息。（有点NameNode的味道） rocketmq-common：通用的一些类，方法，数据结构等 rocketmq-remoting：基于Netty4的client/server + fastjson序列化 + 自定义二进制协议 rocketmq-store：消息、索引存储等 rocketmq-filtersrv：消息过滤器Server，需要注意的是，要实现这种过滤，需要上传代码到MQ！【一般而言，我们利用Tag足以满足大部分的过滤需求，如果更灵活更复杂的过滤需求，可以考虑filtersrv组件】 rocketmq-tools：命令行工具 Order MessageRocketMQ提供了3种模式的Producer： NormalProducer（普通） OrderProducer（顺序） TransactionProducer（事务） 在前面的博客当中，涉及的都是NormalProducer，调用传统的send方法，消息是无序的。接下来，我们来看看顺序消费。模拟这样一个场景，如果一个用户完成一个订单需要3条消息，比如订单的创建、订单的支付、订单的发货，很显然，同一个用户的订单消息必须要顺序消费，但是不同用户之间的订单可以并行消费。 生产者端代码示例： 注意，一个Message除了Topic/Tag外，还有Key的概念。上图的send方法不同于以往，有一个MessageQueueSelector，将用于指定特定的消息发往特定的队列当中！ 注意，在以前普通消费消息时设置的回调是MessageListenerConcurrently，而顺序消费的回调设置是MessageListenerOrderly。 当我们启动2个Consumer进行消费时，可以观察到： 可以观察得到，虽然从全局上来看，消息的消费不是有序的，但是每一个订单下的3条消息是顺序消费的！ 其实，如果需要保证消息的顺序消费，那么很简单，首先需要做到一组需要有序消费的消息发往同一个broker的同一个队列上！其次消费者端采用有序Listener即可。 这里，RocketMQ底层是如何做到消息顺序消费的，看一看源码你就能大概了解到，至少来说，在多线程消费场景下，一个线程只去消费一个队列上的消息，那么自然就保证了消息消费的顺序性，同时也保证了多个线程之间的并发性。也就是说其实broker并不能完全保证消息的顺序消费，它仅仅能保证的消息的顺序发送而已！ 关于多线程消费这块，RocketMQ早就替我们想好了，这样设置即可： 想一想，在ActiveMQ中，我们如果想实现并发消费的话，恐怕还得搞个线程池提交任务吧，RocketMQ让我们的工作变得简单！ Transaction Message在说事务消息之前，我们先来说说分布式事务的那些事！ 什么是分布式事务，我的理解是一半事务。怎么说，比如有2个异构系统，A异构系统要做T1，B异构系统要做T2，要么都成功，要么都失败。要知道异构系统，很显然，不在一个数据库实例上，它们往往分布在不同物理节点上，本地事务已经失效。 2阶段提交协议，Two-Phase Commit，是处理分布式事务的一种常见手段。2PC，存在2个重要角色：事务协调器（TC），事务执行者。 2PC，可以看到节点之间的通信次数太多了，时间很长！时间变长了，从而导致，事务锁定的资源时间也变长了，造成资源等待时间变长！在高并发场景下，存在严重的性能问题 下面，我们来看看MQ在高并发场景下，是如何解决分布式事务的。 考虑生活中的场景： 我们去北京庆丰包子铺吃炒肝，先去营业员那里付款（Action1），拿到小票（Ticket），然后去取餐窗口排队拿炒肝（Action2）。思考2个问题：第一，为什么不在付款的同时，给顾客炒肝？如果这样的话，会增加处理时间，使得后面的顾客等待时间变长，相当于降低了接待顾客的能力（降低了系统的QPS）。第二，付了款，拿到的是Ticket，顾客为什么会接受？从心理上说，顾客相信Ticket会兑现炒肝。事实上也是如此，就算在最后炒肝没了，或者断电断水（系统出现异常），顾客依然可以通过Ticket进行退款操作，这样都不会有什么损失！（虽然这么说，但是实际上包子铺最大化了它的利益，如果炒肝真的没了，浪费了顾客的时间，不过顾客顶多发发牢骚，最后接受） 生活已经告诉我们处理分布式事务，保证数据最终一致性的思路！这个Ticket（凭证）其实就是消息！ 业务操作和消息的生成耦合在一起，保证了只要A银行的账户发生扣款，那么一定会生成一条转账消息。只要A银行系统的事务成功提交，我们可以通过实时消息服务，将转账消息通知B银行系统，如果B银行系统回复成功，那么A银行系统可以在table中设置这条转账消息的状态。 这样耦合的方式，从架构上来看，就有点不太优雅，而且存在一些问题。比如说，消息的存储实质上是在A银行系统中的，如果A银行系统出了问题，将导致无法转账。如果解耦，将消息独立出来呢？ 如上图所示，消息数据独立存储，业务和消息解耦，实质上消息的发送有2次，一条是转账消息，另一条是确认消息。 到这里，我们先来看看基于RocketMQ的代码： 生产者这里用到是：TransactionMQProducer。 这里涉及到2个角色：本地事务执行器（代码中的TransactionExecuterImpl）、服务器回查客户端Listener（代码中的TransactionCheckListener）。 如果事务消息发送到MQ上后，会回调 本地事务执行器；但是此时事务消息是prepare状态，对消费者还不可见，需要 本地事务执行器 返回RMQ一个确认消息。 事务消息是否对消费者可见，完全由事务返回给RMQ的状态码决定（状态码的本质也是一条消息）。 生产者发送了2条消息给RMQ，有一条本地事务执行成功，有一条本地事务执行失败。 2条业务消息 + 2条确认消息 因此是4条； 注意，到消费者只消费了一条数据，就是只有告诉RMQ本地事务执行成功的那条消息才会被消费！因此是1条！ 但是，注意到本地事务执行失败的消息，RMQ并没有check listener？这是为什么呢？因为RMQ在3.0.8的时候还是支持check listener回查机制的，但是到了3.2.6的时候将事务回查机制“阉割”了！ 那么3.0.8的时候，RMQ是怎么做事务回查的呢？看一看源码，你会知道，其实事务消息开始是prepare状态，然后RMQ会将其持久化到MySQL当中，然后如果收到确认消息，就删除掉这条prepare消息，如果迟迟收不到确认消息，那么RMQ会定时的扫描prepare消息，发送给produce group进行回查确认！ 到这里，问题来了，要知道3.2.6版本，没有回查机制了，会存在问题么？ 当然会存在问题！假设，我们发送一条转账事务消息给RMQ，成功后回调本地事务，DB减操作成功，刚准备给RMQ一个确认消息，此时突然断电，或者网络抖动，使得这条确认消息没有发送出去。此时RMQ中的那条转账事务消息，始终处于prepare状态，消费者读取不到，但是却已经完成一方的账户资金变动！！！ 既然，RMQ3.2.6版本不为我们进行回查，那么只能由我们自己完成了。]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ实战（二）]]></title>
    <url>%2Fmq%2Fmq-rocketmq-2%2F</url>
    <content type="text"><![CDATA[Quick Start写一个简单的生产者、消费者，带大家快速体验RocketMQ~ Maven配置： 生产者： 消费者： 无论生产者、消费者都必须给出GroupName，而且具有唯一性！生产到哪个Topic的哪个Tag下，消费者也是从Topic的哪个Tag进行消费，可见这个Tag有点类似于JMS Selector机制，即实现消息的过滤。生产者、消费者需要设置NameServer地址。这里，采用的是Consumer Push的方式，即设置Listener机制回调，相当于开启了一个线程。以后为大家介绍Consumer Pull的方式。 我们看一下运行结果： 仔细看看生产者结果输出，你会发现，有的消息发往broker-a，有的在broker-b上，自动实现了消息的负载均衡！ 这里消费消息是没有什么顺序的，以后我们在来谈消息的顺序性。 在多Master模式中，如果某个Master进程挂了，显然这台broker将不可用，上面的消息也将无法消费，要知道开源版本的RocketMQ是没有提供切换程序，来自动恢复故障的，因此在实际开发中，我们一般提供一个监听程序，用于监控Master的状态。 在ActiveMQ中，生产消息的时候会提供是否持久化的选择，但是对于RocketMQ而言，消息是一定会被持久化的！ 上面的消费者采用的是Push Consumer的方式，那么监听的Listener中的消息List到底是多少条呢？虽然提供了API，如consumer.setConsumeMessageBatchMaxSize(10)，实际上即使设置了批量的条数，但是注意了，是最大是10，并不意味着每次batch的都是10，只有在消息有挤压的情况下才有可能。而且Push Consumer的最佳实践方式就是一条条的消费，如果需要batch，可以使用Pull Consumer。 务必保证先启动消费者进行Topic订阅，然后在启动生产者进行生产（否则极有可能导致消息的重复消费，重复消费，重复消费！重要的事情说三遍！关于消息的重复问题后续给大家介绍~）。而且在实际开发中，有时候不会批量的处理消息，而是原子性的，单线程的去一条一条的处理消息，这样就是实时的在处理消息。（批量的处理海量的消息，可以考虑Kafka） 初步了解消息失败重试机制消息失败，无非涉及到2端：从生产者端发往MQ的失败；消费者端从MQ消费消息的失败； 生产者端的失败重试 生产者端的消息失败：比如网络抖动导致生产者发送消息到MQ失败。 上图代码示例的处理手段是：如果该条消息在1S内没有发送成功，那么重试3次。 消费者端的失败重试 消费者端的失败，分为2种情况，一个是timeout，一个是exceptiontimeout，比如由于网络原因导致消息压根就没有从MQ到消费者上，在RocketMQ内部会不断的尝试发送这条消息，直至发送成功为止！（比如集群中一个broker失败，就尝试另一个broker）exception，消息正常的到了消费者，结果消费者发生异常，处理失败了。这里涉及到一些问题，需要我们思考下，比如，消费者消费消息的状态有哪些定义？如果失败，MQ将采取什么策略进行重试？假设一次性批量PUSH了10条，其中某条数据消费异常，那么消息重试是10条呢，还是1条呢？而且在重试的过程中，需要保证不重复消费吗？ 消息消费的状态，有2种，一个是成功（CONSUME_SUCCESS），一个是失败&amp;稍后重试（RECONSUME_LATER） 在启动broker的过程中，可以观察下日志，你会发现RECONSUME_LATER的策略。 如果消费失败，那么1S后再次消费，如果失败，那么5S后，再次消费，……直至2H后如果消费还失败，那么该条消息就会终止发送给消费者了！ RocketMQ为我们提供了这么多次数的失败重试，但是在实际中也许我们并不需要这么多重试，比如重试3次，还没有成功，我们希望把这条消息存储起来并采用另一种方式处理，而且希望RocketMQ不要在重试呢，因为重试解决不了问题了！这该如何做呢？ 我们先来看一下一条消息MessageExt对象的输出： MessageExt [queueId=0, storeSize=137, queueOffset=0, sysFlag=0, bornTimestamp=1492213846916, bornHost=/192.168.99.219:50478, storeTimestamp=1492213846981, storeHost=/192.168.99.121:10911, msgId=C0A8637900002A9F0000000000000000, commitLogOffset=0, bodyCRC=613185359, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest2, flag=0, properties={TAGS=TagA, WAIT=true, MAX_OFFSET=3, MIN_OFFSET=0}, body=16]] 注意到reconsumeTimes属性，这个属性就代表消息重试的次数！来看一段代码： 注意了，对于消费消息而言，存在2种指定的状态（成功 OR 失败重试），如果一条消息在消费端处理没有返回这2个状态，那么相当于这条消息没有达到消费者，势必会再次发送给消费者！也即是消息的处理必须有返回值，否则就进行重发。 天然的消息负载均衡及高效的水平扩展机制 对于RocketMQ而言，通过ConsumeGroup的机制，实现了天然的消息负载均衡！通俗点来说，RocketMQ中的消息通过ConsumeGroup实现了将消息分发到C1/C2/C3/……的机制，这意味着我们将非常方便的通过加机器来实现水平扩展！ 我们考虑一下这种情况：比如C2发生了重启，一条消息发往C3进行消费，但是这条消息的处理需要0.1S，而此时C2刚好完成重启，那么C2是否可能会收到这条消息呢？答案是肯定的，也就是consume broker的重启，或者水平扩容，或者不遵守先订阅后生产消息，都可能导致消息的重复消费！关于去重的话题会在后续中予以介绍！ 至于消息分发到C1/C2/C3，其实也是可以设置策略的。 集群消费 AND 广播消费 RocketMQ的消费方式有2种，在默认情况下，就是集群消费，也就是上面提及的消息的负载均衡消费。另一种消费模式，是广播消费。广播消费，类似于ActiveMQ中的发布订阅模式，消息会发给Consume Group中的每一个消费者进行消费。]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ实战（一）]]></title>
    <url>%2Fmq%2Fmq-rocketmq-1%2F</url>
    <content type="text"><![CDATA[阿里巴巴有2大核心的分布式技术，一个是OceanBase，另一个就是RocketMQ。在实际项目中已经领教过RocketMQ的强大，本人计划写一个RocketMQ实战系列，将涵盖RocketMQ的简介，环境搭建，初步使用、API详解、架构分析、管理员集群操作等知识。 What is RocketMQ?RocketMQ作为一款分布式的消息中间件（阿里的说法是不遵循任何规范的，所以不能完全用JMS的那一套东西来看它），经历了Metaq1.x、Metaq2.x的发展和淘宝双十一的洗礼，在功能和性能上远超ActiveMQ。 要知道RocketMQ原生就是支持分布式的，而ActiveMQ原生存在单点性。 RocketMQ可以保证严格的消息顺序，而ActiveMQ无法保证！ RocketMQ提供亿级消息的堆积能力，这不是重点，重点是堆积了亿级的消息后，依然保持写入低延迟！ 丰富的消息拉取模式（Push or Pull）Push好理解，比如在消费者端设置Listener回调；而Pull，控制权在于应用，即应用需要主动的调用拉消息方法从Broker获取消息，这里面存在一个消费位置记录的问题（如果不记录，会导致消息重复消费）。 在Metaq1.x/2.x的版本中，分布式协调采用的是Zookeeper，而RocketMQ自己实现了一个NameServer，更加轻量级，性能更好！ 消息失败重试机制、高效的订阅者水平扩展能力、强大的API、事务机制等等（后续详细介绍） 初步理解Producer/Consumer GroupActiveMQ中并没有Group这个概念，而在RocketMQ中理解Group的机制很重要。 想过没有，通过Group机制，让RocketMQ天然的支持消息负载均衡！ 比如某个Topic有9条消息，其中一个Consumer Group有3个实例（3个进程 OR 3台机器），那么每个实例将均摊3条消息！（注意RocketMQ只有一种模式，即发布订阅模式。） RocketMQ的Broker集群部署模式还挺多的，比如单Master模式、多Master模式、多Master多Slave模式（异步复制）、多Master多Slave模式（同步双写）等。明确个概念，RocketMQ Slave不可以写，可以读，类似于MySQL的主从机制。 单Master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！很显然，线上不可以使用。 多Master模式：全是Master，没有Slave。当然，一个broker宕机了，应用是无影响的，缺点在于宕机的Master上未被消费的消息在Master没有恢复之前不可以订阅。 多Master多Slave模式（异步复制）：多对Master-Slave，高可用！采用异步复制的方式，主备之间短暂延迟，MS级别。Master宕机，消费者可以从Slave上进行消费，不受影响，但是Master的宕机，会导致丢失掉极少量的消息。 多Master多Slave模式（同步双写）：和上面的区别点在于采用的是同步方式，也就是在Master/Slave都写成功的前提下，向应用返回成功，可见不论是数据，还是服务都没有单点，都非常可靠！缺点在于同步的性能比异步稍低。 这里我将采用2个Master的方式进行搭建演示，会了双Master，其他的将很简单。（多Master在实际中也是非常常用的，如果并发非常大，考虑多Master多Slave模式） 在192.168.99.121/122机器上各一个NameServer、Master进程。 实例以192.168.99.121为例： 修改/etc/hosts文件 确保相互之间可以ping通 解压并创建存储路径123tar -xvf alibaba-rocketmq-3.2.6.tar.gzmkdir -p alibaba-rocketmq/store/&#123;commitlog,consumequeue,index&#125; 配置文件 上面已经将实际中常用的配置项给出来了！ 修改日志配置文件 注意到logback.*.xml配置文件中： 可以使用sed进行替换： 1sed -i 's#$&#123;user.home&#125;#/software/alibaba-rocketmq#g' *.xml 修改启动脚本中的JVM参数 注意，在这里我将JVM的堆的初始化和最大大小统一设置为1G，并将新生代大小设置为512M。主要是考虑到我的虚拟机内存，实际上在线上是可以走默认的4G堆内存的。 第六步，启动NameServer1nohup sh mqnamesrv &amp; 启动broker-X 注意观察日志： RocketMQ Console把rocketmq-console.war部署到Tomcat下即可。 在解压WAR包后的CLASS下更改config.properties 这个管控台实际上还是比较简陋的，我们使用比较多的是mqadmin操作命令，后续会介绍。]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>mq</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Feign真正正确的使用方法]]></title>
    <url>%2Fjava%2Fjava-feign-1%2F</url>
    <content type="text"><![CDATA[Feign是spring cloud中服务消费端的调用框架,通常与ribbon,hystrix等组合使用。 但是在某些项目中，由于遗留原因，整个系统并不是spring cloud项目，甚至不是spring项目，而使用者关注的重点仅仅是简化http调用代码的编写。 如果采用httpclient或者okhttp这样相对较重的框架，对初学者来说编码量与学习曲线都会是一个挑战，而使用spring中RestTemplate，又没有配置化的解决方案，由此想到是否可以脱离spring cloud，独立使用Feign。 maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-core&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt; 自定义接口12345678import feign.Param;import feign.RequestLine;public interface RemoteService &#123; @RequestLine("GET /users/list?name=&#123;name&#125;") String getOwner(@Param(value = "name") String name);&#125; 通过@RequestLine指定HTTP协议及URL地址 配置类1234RemoteService service = Feign.builder() .options(new Options(1000, 3500)) .retryer(new Retryer.Default(5000, 5000, 3)) .target(RemoteService.class, "http://127.0.0.1:8085"); options方法指定连接超时时长及响应超时时长，retryer方法指定重试策略,target方法绑定接口与服务端地址。返回类型为绑定的接口类型。 调用1String result = service.getOwner("scott"); 与调用本地方法相同的方式调用feign包装的接口，直接获取远程服务提供的返回值。 附：服务生产者12345678910111213141516import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;@Controller@RequestMapping(value="users")public class UserController &#123; @RequestMapping(value="/list",method=&#123;RequestMethod.GET,RequestMethod.POST,RequestMethod.PUT&#125;) @ResponseBody public String list(@RequestParam String name) throws InterruptedException&#123; return name.toUpperCase(); &#125;&#125; 更进一步在项目中，服务消费端与生产端之间交换的数据往往是一或多个对象，feign同样提供基于json的对象转换工具，方便我们直接以对象形式交互。 业务接口123456public interface RemoteService &#123; @Headers(&#123;"Content-Type: application/json","Accept: application/json"&#125;) @RequestLine("POST /users/list") User getOwner(User user);&#125; 加入@Headers注解，指定Content-Type为json 配置123456RemoteService service = Feign.builder() .encoder(new JacksonEncoder()) .decoder(new JacksonDecoder()) .options(new Options(1000, 3500)) .retryer(new Retryer.Default(5000, 5000, 3)) .target(RemoteService.class, "http://127.0.0.1:8085"); encoder指定对象编码方式，decoder指定对象解码方式。这里用的是基于Jackson的编、解码方式，需要在pom.xml中添加Jackson的依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-jackson&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt;&lt;/dependency&gt; 调用1User result = service.getOwner(u); 附：服务生产者12345678910111213@Controller@RequestMapping(value="users")public class UserController &#123; @RequestMapping(value="/list",method=&#123;RequestMethod.GET,RequestMethod.POST,RequestMethod.PUT&#125;) @ResponseBody public User list(@RequestBody User user) throws InterruptedException&#123; System.out.println(user.getUsername()); user.setId(100L); user.setUsername(user.getUsername().toUpperCase()); return user; &#125;&#125; 唯一的变化就是使用了@RequestBody来接收json格式的数据。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出UML类图（五）]]></title>
    <url>%2Fuml%2Fuml-5%2F</url>
    <content type="text"><![CDATA[实例分析3——售票机控制程序某运输公司决定为新的售票机开发车票销售的控制软件。图I给出了售票机的面板示意图以及相关的控制部件。 售票机相关部件的作用如下所述： 目的地键盘用来输入行程目的地的代码（例如，200表示总站）。 乘客可以通过车票键盘选择车票种类（单程票、多次往返票和座席种类）。 继续/取消键盘上的取消按钮用于取消购票过程，继续按钮允许乘客连续购买多张票。 显示屏显示所有的系统输出和用户提示信息。 插卡口接受MCard（现金卡），硬币口和纸币槽接受现金。 打印机用于输出车票。 所有部件均可实现自检并恢复到初始状态。 现采用面向对象方法开发该系统，使用UML进行建模，绘制该系统的初始类图。 参考解决方案参考类图如下： 类说明： 类 名 说 明 Component 抽象部件类，所有部件类的父类 Keyboard 抽象键盘类 ActionKeyboard 继续/取消键盘类 TicketKindKeyboard 车票种类键盘类 DestinationKeyboard 目的地键盘类 Screen 显示屏类 CardDriver 卡驱动器类 CashSlot 现金（硬币/纸币）槽类 Printer 打印机类 TicketSoldSystem 售票系统类 方法说明： 方法名 说 明 Component 的init()方法 初始化部件 Component 的doSeltTest()方法 自检 Keyboard的getSelectedKey()方法 获取按键值 ActionKeyboard的getAction()方法 继续/取消键盘事件处理 TicketKindKeyboard的getTicketKind()方法 车票种类键盘事件处理 DestinationKeyboard的getDestinationCode()方法 目的地键盘事件处理 Screen的showText()方法 显示信息 CardDriver的getCredit()方法 获取金额 CardDriver的debitFare()方法 更新卡余额 CardDriver的ejectMCard()方法 退卡 CashSlot的getCredit()方法 获取金额 Printer的printTicket()方法 打印车票 Printer的ejectTicket()方法 出票 TicketSoldSystem的verifyCredit()方法 验证金额 TicketSoldSystem的calculateFare()方法 计算费用]]></content>
      <categories>
        <category>uml</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出UML类图（四）]]></title>
    <url>%2Fuml%2Fuml-4%2F</url>
    <content type="text"><![CDATA[实例分析1——登录模块某基于C/S的即时聊天系统登录模块功能描述如下： 用户通过登录界面(LoginForm)输入账号和密码，系统将输入的账号和密码与存储在数据库(User)表中的用户信息进行比较，验证用户输入是否正确，如果输入正确则进入主界面(MainForm)，否则提示“输入错误”。 根据以上描述绘制初始类图。 参考解决方案：参考类图如下： 考虑到系统扩展性，在本实例中引入了抽象数据访问接口IUserDAO，再将具体数据访问对象注入到业务逻辑对象中，可通过配置文件（如XML文件）等方式来实现，将具体的数据访问类类名存储在配置文件中，如果需要更换新的具体数据访问对象，只需修改配置文件即可，原有程序代码无须做任何修改。 类说明 类 名 说 明 LoginForm 登录窗口，省略界面组件和按钮事件处理方法（边界类） LoginBO 登录业务逻辑类，封装实现登录功能的业务逻辑（控制类） IUserDAO 抽象数据访问类接口，声明对User表的数据操作方法，省略除查询外的其他方法（实体类） UserDAO 具体数据访问类，实现对User表的数据操作方法，省略除查询外的其他方法（实体类） MainForm 主窗口（边界类） 方法说明 方法名 说 明 LoginForm类的LoginForm()方法 LoginForm构造函数，初始化实例成员 LoginForm类的validate()方法 界面类的验证方法，通过调用业务逻辑类LoginBO的validate()方法实现对用户输入信息的验证 LoginBO类的validate()方法 业务逻辑类的验证方法，通过调用数据访问类的findUserByAccAndPwd()方法验证用户输入信息的合法性 LoginBO类的setIUserDAO()方法 Setter方法，在业务逻辑对象中注入数据访问对象（注意：此处针对抽象数据访问类编程） IUserDAO接口的findUserByAccAndPwd()方法 业务方法声明，通过用户账号和密码在数据库中查询用户信息，判断该用户身份的合法性 UserDAO类的findUserByAccAndPwd()方法 业务方法实现，实现在IUserDAO接口中声明的数据访问方法 实例分析2——注册模块某基于Java语言的C/S软件需要提供注册功能，该功能简要描述如下： 用户通过注册界面(RegisterForm)输入个人信息，用户点击“注册”按钮后将输入的信息通过一个封装用户输入数据的对象(UserDTO)传递给操作数据库的数据访问类，为了提高系统的扩展性，针对不同的数据库可能需要提供不同的数据访问类，因此提供了数据访问类接口，如IUserDAO，每一个具体数据访问类都是某一个数据访问类接口的实现类，如OracleUserDAO就是一个专门用于访问Oracle数据库的数据访问类。 根据以上描述绘制类图。为了简化类图，个人信息仅包括账号(userAccount)和密码(userPassword)，且界面类无需涉及界面细节元素。 参考解决方案在以上功能说明中，可以分析出该系统包括三个类和一个接口，这三个类分别是注册界面类RegisterForm、用户数据传输类UserDTO、Oracle用户数据访问类OracleUserDAO，接口是抽象用户数据访问接口IUserDAO。它们之间的关系如下： 在RegisterForm中需要使用UserDTO类传输数据且需要使用数据访问类来操作数据库，因此RegisterForm与UserDTO和IUserDAO之间存在关联关系，在RegisterForm中可以直接实例化UserDTO，因此它们之间可以使用组合关联。 由于数据库类型需要灵活更换，因此在RegisterForm中不能直接实例化IUserDAO的子类，可以针对接口IUserDAO编程，再通过注入的方式传入一个IUserDAO接口的子类对象（在本书后续章节中将学习如何具体实现），因此RegisterForm和IUserDAO之间具有聚合关联关系。 OracleUserDAO是实现了IUserDAO接口的子类，因此它们之间具有类与接口的实现关系。 在声明IUserDAO接口的增加用户信息方法addUser()时，需要将在界面类中实例化的UserDTO对象作为参数传递进来，然后取出封装在UserDTO对象中的数据插入数据库，因此addUser()方法的函数原型可以定义为：public boolean addUser(UserDTO user)，在IUserDAO的方法addUser()中将UserDTO类型的对象作为参数，故IUserDAO与UserDTO存在依赖关系。 通过以上分析，该实例参考类图如图1所示： 注意：在绘制类图或其他UML图形时，可以通过注释(Comment)来对图中的符号或元素进行一些附加说明，如果需要详细说明类图中的某一方法的功能或者实现过程，可以使用如图2所示表示方式：]]></content>
      <categories>
        <category>uml</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出UML类图（三）]]></title>
    <url>%2Fuml%2Fuml-3%2F</url>
    <content type="text"><![CDATA[类与类之间的关系（2）依赖关系依赖(Dependency)关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他事物，在需要表示一个事物使用另一个事物时使用依赖关系。大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。例如：驾驶员开车，在Driver类的drive()方法中将Car类型的对象car作为一个参数传递，以便在drive()方法中能够调用car的move()方法，且驾驶员的drive()方法依赖车的move()方法，因此类Driver依赖类Car，如图1所示： 在系统实施阶段，依赖关系通常通过三种方式来实现，第一种也是最常用的一种方式是如图1所示的将一个类的对象作为另一个类中方法的参数，第二种方式是在一个类的方法中将另一个类的对象作为其局部变量，第三种方式是在一个类的方法中调用另一个类的静态方法。图1对应的Java代码片段如下： 12345678910111213public class Driver &#123; public void drive(Car car) &#123; car.move(); &#125; …… &#125; public class Car &#123; public void move() &#123; ...... &#125; …… &#125; 泛化关系泛化(Generalization)关系也就是继承关系，用于描述父类与子类之间的关系，父类又称作基类或超类，子类又称作派生类。在UML中，泛化关系用带空心三角形的直线来表示。在代码实现时，我们使用面向对象的继承机制来实现泛化关系，如在Java语言中使用extends关键字、在C++/C#中使用冒号“：”来实现。例如：Student类和Teacher类都是Person类的子类，Student类和Teacher类继承了Person类的属性和方法，Person类的属性包含姓名(name)和年龄(age)，每一个Student和Teacher也都具有这两个属性，另外Student类增加了属性学号(studentNo)，Teacher类增加了属性教师编号(teacherNo)，Person类的方法包括行走move()和说话say()，Student类和Teacher类继承了这两个方法，而且Student类还新增方法study()，Teacher类还新增方法teach()。如图2所示： 图2对应的Java代码片段如下： 12345678910111213141516171819202122232425262728293031//父类 public class Person &#123; protected String name; protected int age; public void move() &#123; …… &#125; public void say() &#123; …… &#125; &#125; //子类 public class Student extends Person &#123; private String studentNo; public void study() &#123; …… &#125; &#125; //子类 public class Teacher extends Person &#123; private String teacherNo; public void teach() &#123; …… &#125; &#125; 接口与实现关系在很多面向对象语言中都引入了接口的概念，如Java、C#等，在接口中，通常没有属性，而且所有的操作都是抽象的，只有操作的声明，没有操作的实现。UML中用与类的表示法类似的方式表示接口，如图3所示： 接口之间也可以有与类之间关系类似的继承关系和依赖关系，但是接口和类之间还存在一种实现(Realization)关系，在这种关系中，类实现了接口，类中的操作实现了接口中所声明的操作。在UML中，类与接口之间的实现关系用带空心三角形的虚线来表示。例如：定义了一个交通工具接口Vehicle，包含一个抽象操作move()，在类Ship和类Car中都实现了该move()操作，不过具体的实现细节将会不一样，如图4所示： 实现关系在编程实现时，不同的面向对象语言也提供了不同的语法，如在Java语言中使用implements关键字，而在C++/C#中使用冒号“：”来实现。图4对应的Java代码片段如下： 123456789101112131415public interface Vehicle &#123; public void move(); &#125; public class Ship implements Vehicle &#123; public void move() &#123; …… &#125; &#125; public class Car implements Vehicle &#123; public void move() &#123; …… &#125; &#125;]]></content>
      <categories>
        <category>uml</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出UML类图（二）]]></title>
    <url>%2Fuml%2Fuml-2%2F</url>
    <content type="text"><![CDATA[类与类之间的关系（1）在软件系统中，类并不是孤立存在的，类与类之间存在各种关系，对于不同类型的关系，UML提供了不同的表示方式。 关联关系关联(Association)关系是类与类之间最常用的一种关系，它是一种结构化关系，用于表示一类对象与另一类对象之间有联系，如汽车和轮胎、师傅和徒弟、班级和学生等等。在UML类图中，用实线连接有关联关系的对象所对应的类，在使用Java、C#和C++等编程语言实现关联关系时，通常将一个类的对象作为另一个类的成员变量。在使用类图表示关联关系时可以在关联线上标注角色名，一般使用一个表示两者之间关系的动词或者名词表示角色名（有时该名词为实例对象名），关系的两端代表两种不同的角色，因此在一个关联关系中可以包含两个角色名，角色名不是必须的，可以根据需要增加，其目的是使类之间的关系更加明确。 如在一个登录界面类LoginForm中包含一个JButton类型的注册按钮loginButton，它们之间可以表示为关联关系，代码实现时可以在LoginForm中定义一个名为loginButton的属性对象，其类型为JButton。如图1所示： 图1对应的Java代码片段如下： 12345678public class LoginForm &#123; private JButton loginButton; //定义为成员变量 …… &#125; public class JButton &#123; …… &#125; 在UML中，关联关系通常又包含如下几种形式： 双向关联默认情况下，关联是双向的。例如：顾客(Customer)购买商品(Product)并拥有商品，反之，卖出的商品总有某个顾客与之相关联。因此，Customer类和Product类之间具有双向关联关系，如图2所示： 图2对应的Java代码片段如下： 123456789public class Customer &#123; private Product[] products; …… &#125; public class Product &#123; private Customer customer; …… &#125; 单向关联类的关联关系也可以是单向的，单向关联用带箭头的实线表示。例如：顾客(Customer)拥有地址(Address)，则Customer类与Address类具有单向关联关系，如图3所示： 图3对应的Java代码片段如下： 12345678public class Customer &#123; private Address address; …… &#125; public class Address &#123; …… &#125; 自关联在系统中可能会存在一些类的属性对象类型为该类本身，这种特殊的关联关系称为自关联。例如：一个节点类(Node)的成员又是节点Node类型的对象，如图4所示： 图4对应的Java代码片段如下： 1234public class Node &#123; private Node subNode; …… &#125; 多重性关联多重性关联关系又称为重数性(Multiplicity)关联关系，表示两个关联对象在数量上的对应关系。在UML中，对象之间的多重性可以直接在关联直线上用一个数字或一个数字范围表示。 对象之间可以存在多种多重性关联关系，常见的多重性表示方式如表1所示： 表示方式 多重性说明 1..1 表示另一个类的一个对象只与该类的一个对象有关系 0..* 表示另一个类的一个对象与该类的零个或多个对象有关系 1..* 表示另一个类的一个对象与该类的一个或多个对象有关系 0..1 表示另一个类的一个对象没有或只与该类的一个对象有关系 m..n 表示另一个类的一个对象与该类最少m，最多n个对象有关系 (m≤n) 例如：一个界面(Form)可以拥有零个或多个按钮(Button)，但是一个按钮只能属于一个界面，因此，一个Form类的对象可以与零个或多个Button类的对象相关联，但一个Button类的对象只能与一个Form类的对象关联，如图5所示： 图5对应的Java代码片段如下： 12345678public class Form &#123; private Button[] buttons; //定义一个集合对象 …… &#125; public class Button &#123; …… &#125; 聚合关系聚合(Aggregation)关系表示整体与部分的关系。在聚合关系中，成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。例如：汽车发动机(Engine)是汽车(Car)的组成部分，但是汽车发动机可以独立存在，因此，汽车和发动机是聚合关系，如图6所示： 在代码实现聚合关系时，成员对象通常作为构造方法、Setter方法或业务方法的参数注入到整体对象中，图6对应的Java代码片段如下： 123456789101112131415161718public class Car &#123; private Engine engine; //构造注入 public Car(Engine engine) &#123; this.engine = engine; &#125; //设值注入 public void setEngine(Engine engine) &#123; this.engine = engine; &#125; …… &#125; public class Engine &#123; …… &#125; 组合关系组合(Composition)关系也表示类之间整体和部分的关系，但是在组合关系中整体对象可以控制成员对象的生命周期，一旦整体对象不存在，成员对象也将不存在，成员对象与整体对象之间具有同生共死的关系。在UML中，组合关系用带实心菱形的直线表示。例如：人的头(Head)与嘴巴(Mouth)，嘴巴是头的组成部分之一，而且如果头没了，嘴巴也就没了，因此头和嘴巴是组合关系，如图7所示： 在代码实现组合关系时，通常在整体类的构造方法中直接实例化成员类，图7对应的Java代码片段如下： 123456789101112public class Head &#123; private Mouth mouth; public Head() &#123; mouth = new Mouth(); //实例化成员类 &#125; …… &#125; public class Mouth &#123; …… &#125;]]></content>
      <categories>
        <category>uml</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出UML类图（一）]]></title>
    <url>%2Fuml%2Fuml-1%2F</url>
    <content type="text"><![CDATA[在UML 2.0的13种图形中，类图是使用频率最高的UML图之一。Martin Fowler在其著作《UML Distilled: A Brief Guide to the Standard Object Modeling Language, Third Edition》（《UML精粹：标准对象建模语言简明指南（第3版）》）中有这么一段：“If someone were to come up to you in a dark alley and say, ‘Psst, wanna see a UML diagram?’ that diagram would probably be a class diagram. The majority of UML diagrams I see are class diagrams.”（“如果有人在黑暗的小巷中向你走来并对你说：‘嘿，想不想看一张UML图？’那么这张图很有可能就是一张类图，我所见过的大部分的UML图都是类图”），由此可见类图的重要性。 类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。 类类(Class)封装了数据和行为，是面向对象的重要组成部分，它是具有相同属性、操作、关系的对象集合的总称。在系统中，每个类都具有一定的职责，职责指的是类要完成什么样的功能，要承担什么样的义务。一个类可以有多种职责，设计得好的类一般只有一种职责。在定义类的时候，将类的职责分解成为类的属性和操作（即方法）。类的属性即类的数据职责，类的操作即类的行为职责。设计类是面向对象设计中最重要的组成部分，也是最复杂和最耗时的部分。 在软件系统运行时，类将被实例化成对象(Object)，对象对应于某个具体的事物，是类的实例(Instance)。 类图(Class Diagram)使用出现在系统中的不同类来描述系统的静态结构，它用来描述不同的类以及它们之间的关系。 在系统分析与设计阶段，类通常可以分为三种，分别是实体类(Entity Class)、控制类(Control Class)和边界类(Boundary Class)，下面对这三种类加以简要说明： 实体类：实体类对应系统需求中的每个实体，它们通常需要保存在永久存储体中，一般使用数据库表或文件来记录，实体类既包括存储和传递数据的类，还包括操作数据的类。实体类来源于需求说明中的名词，如学生、商品等。 控制类：控制类用于体现应用程序的执行逻辑，提供相应的业务操作，将控制类抽象出来可以降低界面和数据库之间的耦合度。控制类一般是由动宾结构的短语（动词+名词）转化来的名词，如增加商品对应有一个商品增加类，注册对应有一个用户注册类等。 边界类：边界类用于对外部用户与系统之间的交互对象进行抽象，主要包括界面类，如对话框、窗口、菜单等。 在面向对象分析和设计的初级阶段，通常首先识别出实体类，绘制初始类图，此时的类图也可称为领域模型，包括实体类及其它们之间的相互关系。 类的UML图示在UML中，类使用包含类名、属性和操作且带有分隔线的长方形来表示，如定义一个Employee类，它包含属性name、age和email，以及操作modifyInfo()，在UML类图中该类如图1所示： 图1对应的Java代码片段如下： 123456789public class Employee &#123; private String name; private int age; private String email; public void modifyInfo() &#123; ...... &#125; &#125; 在UML类图中，类一般由三部分组成： 第一部分是类名：每个类都必须有一个名字，类名是一个字符串。 第二部分是类的属性(Attributes)：属性是指类的性质，即类的成员变量。一个类可以有任意多个属性，也可以没有属性。 UML规定属性的表示方式为：(可见性 名称:类型 [ = 缺省值 ])其中： 可见性”表示该属性对于类外的元素而言是否可见，包括公有(public)、私有(private)和受保护(protected)三种，在类图中分别用符号+、-和#表示。 “名称”表示属性名，用一个字符串表示。 “类型”表示属性的数据类型，可以是基本数据类型，也可以是用户自定义类型。 “缺省值”是一个可选项，即属性的初始值。 第三部分是类的操作(Operations)：操作是类的任意一个实例对象都可以使用的行为，是类的成员方法。 UML规定操作的表示方式为：(可见性 名称(参数列表) [ : 返回类型])其中： “可见性”的定义与属性的可见性定义相同。 “名称”即方法名，用一个字符串表示。 “参数列表”表示方法的参数，其语法与属性的定义相似，参数个数是任意的，多个参数之间用逗号“，”隔开。 “返回类型”是一个可选项，表示方法的返回值类型，依赖于具体的编程语言，可以是基本数据类型，也可以是用户自定义类型，还可以是空类型(void)，如果是构造方法，则无返回类型。 在类图2中，操作method1的可见性为public(+)，带入了一个Object类型的参数par，返回值为空(void)；操作method2的可见性为protected(#)，无参数，返回值为String类型；操作method3的可见性为private(-)，包含两个参数，其中一个参数为int类型，另一个为int[]类型，返回值为int类型。 由于在Java语言中允许出现内部类，因此可能会出现包含四个部分的类图，如图3所示：]]></content>
      <categories>
        <category>uml</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说分布式事务(五)]]></title>
    <url>%2Fjava%2Fjava-transaction-5%2F</url>
    <content type="text"><![CDATA[业务回补场景业务对资金进行操作 简化流程整个资金平台会和支付宝进行交互(冻结金额,出账金额),对这两个动作支付宝都会返回成功或者失败,当然还有异常流接口超时(实际成功/实际失败). 正常流的业务,我们都可以根据实际的返回进行自己业务逻辑的处理,但是异常流对于调用方其实不知道实际结果,这个时候就需要进行业务数据回补,丰富一下调用时序图 对资金进行操作以后,如果最终是成功的话,都会发送相应的成功消息,业务可以根据实际情况接受消息进行处理,对应的流程图为 自身业务,需要监听调用方的业务消息,因为会出现接口返回失败(比如说接口超时),但是实际成功的场景,通过监听成功消息进行流程回溯 问题 涉及异步更新的操作,都会存在短暂的状态不一致的情况,当数据处于中间状态,可能会出现业务重复提交的情况,这个就需要业务上规避类似的问题(比如对于资金会加入审核流程)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说分布式事务(四)]]></title>
    <url>%2Fjava%2Fjava-transaction-4%2F</url>
    <content type="text"><![CDATA[最终一致性(二)基于MQ的分布式事务补偿机制序列图 异常场景处理 预创建订单失败:如果实际预创建订单成功,订单定时补偿机制,定时删除这部分订单,不影响数据一致性,下单失败 预扣减库存失败:如果预扣减库存真实失败,则下单失败(订单由定时补偿机制定时删除,其它应用参照场景4的处理方式,下单失败;如果实际预扣减库存成功,参照场景4的处理方式,下单失败 实际创建订单失败:如果创建订单真实失败(不需要发送下单失败消息,防止实际创建订单成功场景),订单的预处理数据通过订单的定时补偿机制尝试删除(需要考虑事务处理时间,将超过某个时间范围该事务还处于预处理状态的订单删除),下单失败;如果实际创建订单成功,其它应用参照场景4的处理方式,下单成功(提示用户下单失败) 发送订单创建成功消息失败/库存服务由于各种原因没有接到下单成功消息:库存服务定时轮询处理数据(需要考虑事务处理时间,将超过某个时间范围该事务还处于预处理状态的订单筛选出来),询问订单服务改订单Id对应的订单是否创建成功,根据订单创建成功与否选取相应的事务补偿机制 和TCC的比较 TCC是把所有的订单创建步骤平等看待,只要有一个失败,整个下单流程全部失败(比较TCC里面的confirm失败和基于MQ实际创建订单失败的补偿难易程度) TCC是通过发消息给TCC服务器,然后由TCC服务调用应用服务;基于MQ的分布式事务补偿机制,是通过将消息发送到MQ,然后由应用自己去监听MQ的事件]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说分布式事务(三)]]></title>
    <url>%2Fjava%2Fjava-transaction-3%2F</url>
    <content type="text"><![CDATA[最终一致性(一)TCC简介TCC是由支付宝架构师提供的一种柔性解决分布式事务解决方案,主要包括三个步骤: TCC流程TCC的关键流程如下图(以下单和扣减库存为例子) Q: 预生成订单失败了,为什么要通过TCC执行预处理数据回滚?A: 可能预生成订单成功,但是接口返回失败(超时失败),所以预处理在某些情况下是有预处理数据,需要清理 TCC异常场景在整个流程,我们主要需要关注的是cancel失败和confirm失败引起的数据不一致现象 注意事项 TCC服务支持接口失败重试,所以对TCC暴露的接口都需要满足幂等性(根据事务Id很好满足) 基于TCC的中心化事务一致性解决方法,各个应用服务器如果需要感知某次事务是否成功的成本很高,所以对于自身而言进行事务补偿成本就会很高.举个例子: 后记 是否一定需要TCC服务器? 不一定,可以让交易链路来充当TCC服务器的角色,但是长期来看,TCC相当于是一个公用的组件,所以其它地方也需要TCC分布式事务,可以公用这一个组件(交易链路可以完成TCC所能完成的一切操作,把TCC单独部署一个服务,仅仅是考虑整个系统的抽象结构和功能复用) 这里说的预处理,指的是什么? 在整个分布式事务中预处理的含义其实很广泛,比如订单,所谓的预处理就是生成订单,但是用户真实是看不到这些订单的,至于具体实现是在一张新表中记录还是在原有的订单表是加上标记位,具体实现方式由自己统筹考虑(当然还需要考虑记录事务Id);像减库存这种预处理,可以直接减少原始库存,再通过另外一张表来记录这次事务Id操作了哪个Sku的库存数量,当然也可以不减少库存只记录操作,但是这种方式在计算实际库存的时候复杂度会提高(需要减掉预处理的那部分)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说分布式事务(二)]]></title>
    <url>%2Fjava%2Fjava-transaction-2%2F</url>
    <content type="text"><![CDATA[3PC 以两阶段提交来说，主持人收到一个提案请求，打电话跟每个组员询问是否通过并统计回复，然后将最后决定打电话通知各组员。要是主持人在跟第一位组员通完电话后失忆，而第一位组员在得知结果并执行后老人痴呆，那么即使重新选出主持人，也没人知道最后的提案决定是什么，也许是通过，也许是驳回，不管大家选择哪一种决定，都有可能与第一位组员已执行过的真实决定不一致，老板就会不开心认为决策小组沟通有问题而解雇。三阶段提交即是引入了另一个步骤，主持人打电话跟组员通知请准备通过提案，以避免没人知道真实决定而造成决定不一致的失业危机。为什么能够解决二阶段提交的问题呢？回到刚刚提到的状况，在主持人通知完第一位组员请准备通过后两人意外失忆，即使没人知道全体在第一阶段的决定为何，全体决策组员仍可以重新协调过程或直接否决，不会有不一致决定而失业。那么当主持人通知完全体组员请准备通过并得到大家的再次确定后进入第三阶段，当主持人通知第一位组员请通过提案后两人意外失忆，这时候其他组员再重新选出主持人后，仍可以知道目前至少是处于准备通过提案阶段，表示第一阶段大家都已经决定要通过了，此时便可以直接通过 以上资料来自wiki百科,说明在2PC过程中,在第二个阶段当协调者通知第一个客户端A,并且第一个客户端刚好执行完毕以后,这两台机器都Down掉了,而恰好这N-1台机器投的都是Yes票(都处于不确定的状态),这个时候整个事务就会被Block,暂时称之为聋哑事件 客户端A投的是Abort票,那么由于协调者和客户端A都Down掉,那么整个事务应该是abort 客户端A投的是commit票,并且协调者决定commit,那么整个事务应该是commit 客户端A投的是commit票,并且协调者由于自身的原因决定abort,那么整个事务应该是abort 在3PC中引入了一个预提交的状态 当在第二阶段出现聋哑事件,那么这N-1台机器可以根据超时机制直接abort掉,因为客户端A如果提交了事务,只是预提交,当该机器重启以后只要询问周边机器事务状态,简单的将事务回滚或者提交事务,就能保持事务的最终一致性 当进行到第三阶段的时候,如果发生聋哑事件,那么其它处于「不确定状态」的客户端会直接执行commit,而不会像2PC一样导致事务block,但是这样会有一个风险(进入到第三个阶段说明客户端在第一阶段投的都是Yes),因为在聋哑事件中,那台Down掉的机器在第二阶段中给协调者发送的不是prepared,这个时候协调者收到消息给客户端发送的是abort命令.所以3PC只是乐观的认为只要你第一阶段大家投的都是Yes,那么最后成功提交的几率很大]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说分布式事务(一)]]></title>
    <url>%2Fjava%2Fjava-transaction-1%2F</url>
    <content type="text"><![CDATA[2PC(两阶段事务提交)两阶段事务提交简化图 两阶段事务提交异常点 节点本身故障(比如Down机) 节点之间通信故障 两阶段事务提交错误点分析 说明 图中有问号的条目,是我不确定的地方,但是不影响这个分布式事务的结果 图中的感叹号条目,个人感觉其实也是允许先发消息再记录日志的,但是如果这样子做以后发生Down机,客户端或者TM都需要向其它机器询问结果才能得到结论(而这样子做的话会大大加长分布事务的阻塞时间和事务处理的复杂度,同时这样做会有一个致命的缺陷,抹除了一部分可以自恢复场景。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sonarqube和mvn整合]]></title>
    <url>%2Fjava%2Fjava-sonarqube-1%2F</url>
    <content type="text"><![CDATA[SonarQube(Sonar)是一个用于管理代码质量的开源平台。SonarQube目前已支持超过20种主流编程语言，它管理的代码质量主要涉及7个维度:架构与设计、重复、单元测试、复杂度、潜在的bug、代码标准、注释。 本文，笔者将围绕搭建SonarQube这样的代码质量管理平台这个主题展开，结合java代码实例一步步讲述具体的过程，其中涉及Sonar的下载安装、创建对应Mysql数据库以及运行和管理，并对实践过程中出现的一些问题进行了分析和解决。 注：本文中所有的实践都是在Docker虚拟机下进行，但目测同样适用于各个平台。 安装postgres数据库 12345678910postgres: image: registry.cn-shenzhen.aliyuncs.com/zhouqi/postgres:1.0 environment: - POSTGRES_USER=root - POSTGRES_PASSWORD=000000 ports: - "5432:5432" container_name: postgres 安装sonarqube 1234567891011121314sonarqube: image: registry.cn-shenzhen.aliyuncs.com/zhouqi/sonarqube:2.0 depends_on: - postgres environment: - SONARQUBE_JDBC_USERNAME=root - SONARQUBE_JDBC_PASSWORD=000000 - SONARQUBE_JDBC_URL=jdbc:postgresql://192.168.137.60/sonar ports: - "9000:9000" - "9092:9092" container_name: sonarqube 配置maven 12345678910111213141516171819&lt;settings&gt; &lt;pluginGroups&gt; &lt;pluginGroup&gt;org.sonarsource.scanner.maven&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;!-- Optional URL to server. Default value is http://localhost:9000 --&gt; &lt;sonar.host.url&gt; http://myserver:9000 &lt;/sonar.host.url&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/settings&gt; idea运行 12mvn installmvn sonar:sonar]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7升级后无法重启或关机解决办法]]></title>
    <url>%2Flinux%2Flinux-centos-1%2F</url>
    <content type="text"><![CDATA[由于CentOS7新发布的yum源升级包中systemd关机流程判断条件发生了变化，可能会导致centos7升级后，服务器重启时卡死。新发布的systemd进程的判断更加严格，如果某些进程不响应SIGTERM信号，可能会导致重启是挂死。该问题和业务进程对SIGTERM信号的处理有关。 执行yum update systemd（或者yum update）将systemd系列软件包更新到219-19.el7版本之后，reboot会出现如下卡机界面导致系统挂住，无法重启： 现象： 查询版本包： 解决办法： 新建/etc/systemd/system/rc-local.service并写入： 12345678910[Unit]Description=/etc/rc.d/rc.local CompatibilityConditionFileIsExecutable=/etc/rc.d/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.d/rc.local startTimeoutSec=5RemainAfterExit=yes 备份/etc/systemd/system.conf1cp -a /etc/systemd/system.conf /etc/systemd/system.conf_bak 修改文件1sed -i 's/#DefaultTimeoutStopSec=90s/DefaultTimeoutStopSec=30s/g' /etc/systemd/system.conf 重新加载1systemctl daemon-reload]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[适配器模式之对象适配器]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2Fdesign-pattern-1%2F</url>
    <content type="text"><![CDATA[问题导入：比如有A型螺母和B型螺母，那么用户可以再A型螺母上直接使用按着A型螺母生产的A型螺丝，同样也可以在B型螺母上直接使用按着B型螺母标准生产的B型螺丝。但是由于A型螺母和B型螺母的标准不一样，用户在A型螺母上不能直接使用B型的螺丝，反之也一样。该如何达到这个目的呢？ 使用适配器就可以解决这个问题：生产一种“A型螺母适配器”，这种A型螺母适配器的前端符合A型螺母标准要求，可以拧在A型螺母上，后端又焊接了一个B型螺母。这样用户就可以借助A型螺母适配器在A型螺母上使用B型的螺丝了。 适配器模式又称为包装器，是用来将一个类的接口转换成客户希望的另外一个接口。这可以使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。适配器模式的关键是建立一个适配器，这个适配器实现了目标接口并且包含了被适配者的引用。 适配器模式的三种角色： 目标：目标是一个接口，该接口是客户想要使用的接口。 被适配者：被适配者是一个已经存在的接口或抽象类，这个接口接口或者抽象类需要适配。 适配器：适配器是一个类，该类实现了目标接口并且包含有被适配者的引用，即适配器的职责是对适配者接口或抽象类与目标接口进行适配。 以下通过一个简单的问题来描述适配器模式中所涉及的各个角色。 实例用户已经有一个两厢的插座，但是最近用户又有了一个新的三厢插座。用户现有一台洗衣机和一台电视机，洗衣机是三厢插头，而电视机是两厢插头。现在用户想用心的三厢插座来使用洗衣机和电视机，即用心的三厢插座为洗衣机和电视机接通电流。 针对以上问题，使用适配器模式设计若干个类。 目标 本问题是使用三厢插座来为电视机和洗衣机接通电流，所以目标是三厢插座。把三厢插座设置为一个接口： 123456package com.adatpe;//适配目标：三相插座public interface ThreeElectricOutlet &#123; void connectElectricCurrent();&#125; 被适配者 对于本问题，用户是想要用三厢插座为两厢插头的电视机接通电流，所以被适配者应该是两厢插座，也设置为一个接口： 123456package com.adatpe;//被适配者：两相插座public interface TwoElectricOutlet &#123; void connectElectricCurrent();&#125; 适配器 该适配器实现了目标接口三厢插座ThreeElectricOutlet，同时又包含了两厢插座TwoElectricOutlet的引用： 1234567891011121314package com.adatpe;//适配器：实现目标接口public class ThreeElectricAdapter implements ThreeElectricOutlet &#123; //适配器包含被适配者的引用 private TwoElectricOutlet outlet; public ThreeElectricAdapter(TwoElectricOutlet outlet) &#123; this.outlet = outlet; &#125; public void connectElectricCurrent() &#123; outlet.connectElectricCurrent(); &#125;&#125; 下列应用程序中，Application.java使用了适配器模式中所涉及的类，应用程序负责用Wash类创建一个对象来模拟一台洗衣机，使用TV类创建一个对象来模拟一台电视机 使用ThreeElectricOutlet接口变量调用Wash对象的connectElectricCurrent()方法，并借助适配器调用TV对象的connectElectricCurrent()方法，即用三厢插座分别为洗衣机和电视机接通电流。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.adatpe; public class Application &#123; public static void main(String[] args) &#123; ThreeElectricOutlet outlet; //目标接口（三相插座） Wash wash = new Wash(); //洗衣机 outlet = wash; //洗衣机插在三相插座上 System.out.println("使用三相插座接通电流"); outlet.connectElectricCurrent(); //接通电流开始洗衣服 TV tv = new TV(); //电视机 ThreeElectricAdapter adapter = new ThreeElectricAdapter(tv); //把电视插在适配器上面 outlet = adapter; //再把适配器插在三厢插座上 System.out.println("使用三厢插座接通电流"); outlet.connectElectricCurrent(); //接通电流，开始播放电视节目 &#125;&#125;//洗衣机使用三相插座class Wash implements ThreeElectricOutlet&#123; private String name; public Wash() &#123; name = "黄河洗衣机"; &#125; public Wash(String name)&#123; this.name = name; &#125; public void connectElectricCurrent() &#123; turnOn(); &#125; public void turnOn()&#123; System.out.println(name+"开始洗衣服了"); &#125;&#125;//电视机使用两厢插座class TV implements TwoElectricOutlet&#123; private String name; public TV() &#123; name = "长江电视机"; &#125; public TV(String name)&#123; this.name = name; &#125; public void connectElectricCurrent() &#123; turnOn(); &#125; public void turnOn()&#123; System.out.println(name+"开始播放电视节目"); &#125;&#125; 运行结果为： 使用三相插座接通电流黄河洗衣机开始洗衣服了使用三厢插座接通电流长江电视机开始播放电视节目 双向适配器在适配器模式中，如果Adapter角色同时实现目标接口和被适配者接口，并包含目标接口和被适配接口的引用，那么该适配器就是一个双向适配器。使用双向适配器，用户既可以用新的接口又可以用已有的接口。在以上例子中，如果用户希望能有三厢插座来接通洗衣机和电视机的电流，有可以用两厢插座来接通洗衣机和电视机的电流，那么就必须使用一个双向适配器。具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637package com.adatpe;public class ThreeAndTwoElectricAdapter implements ThreeElectricOutlet, TwoElectricOutlet &#123; private ThreeElectricOutlet threeElectricOutlet; private TwoElectricOutlet twoElectricOutlet; public ThreeAndTwoElectricAdapter(ThreeElectricOutlet threeOutlet,TwoElectricOutlet twoOutlet) &#123; threeElectricOutlet = threeOutlet; twoElectricOutlet = twoOutlet; &#125; public ThreeAndTwoElectricAdapter(TwoElectricOutlet twoOutlet,ThreeElectricOutlet threeOutlet)&#123; threeElectricOutlet = threeOutlet; twoElectricOutlet = twoOutlet; &#125; public void connectElectricCurrent() &#123; if(this instanceof ThreeElectricOutlet)&#123; twoElectricOutlet.connectElectricCurrent();//twoElectricOutlet是被适配的接口 &#125; if(this instanceof TwoElectricOutlet)&#123; threeElectricOutlet.connectElectricCurrent(); //threeElectricOutlet是被适配的接口 &#125; &#125; public static void main(String[] args) &#123; ThreeElectricOutlet threeOutlet; TwoElectricOutlet twOutlet; Wash wash = new Wash(); TV tv = new TV(); ThreeAndTwoElectricAdapter adapter = new ThreeAndTwoElectricAdapter(wash,tv); threeOutlet = adapter; System.out.println("使用三厢插座接通电源"); threeOutlet.connectElectricCurrent(); twOutlet = adapter; System.out.println("使用两厢插座接通电源"); twOutlet.connectElectricCurrent(); &#125;&#125; 运行结果为： 使用三厢插座接通电源长江电视机开始播放电视节目黄河洗衣机开始洗衣服了使用两厢插座接通电源长江电视机开始播放电视节目黄河洗衣机开始洗衣服了 这样就实现了即可以用三厢插座又可以用两厢插座来为电视机和洗衣机接通电流了。 优点 目标和被适配者是完全解耦的关系。 适配器模式满足“开–闭原则”，当添加一个实现了Adapter接口的新类时，不必修改Adapter，Adapter就能对这个新类的实例进行适配。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于MapStruct转换list的问题]]></title>
    <url>%2Fjava%2Fjava-MapStruct-2%2F</url>
    <content type="text"><![CDATA[mapstruct在转换list之前必须有一个前置转换，即他们的实体之间的转换 错误的转换方式：1List&lt;EggVo&gt; listpoTovo(List&lt;Egg&gt; po); 正确的转换方式： 1234@Mapping(source = "id", target = "lid")EggVo poTovo(Egg po);List&lt;EggVo&gt; listpoTovo(List&lt;Egg&gt; po); 添加了实体转换之后，就可以正常的进行list转换了，同理把属性映射直接加在list转换上也是不行的，要加在实体转换上，然后list的转换也会继承这和属性的映射。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mapstruct</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok介绍]]></title>
    <url>%2Fjava%2Fjava-Lombok%2F</url>
    <content type="text"><![CDATA[背景我们在开发过程中，通常都会定义大量的JavaBean，然后通过IDE去生成其属性的构造器、getter、setter、equals、hashcode、toString方法，当要对某个属性进行改变时，比如命名、类型等，都需要重新去生成上面提到的这些方法，那Java中有没有一种方式能够避免这种重复的劳动呢？答案是有，我们来看一下下面这张图，右面是一个简单的JavaBean，只定义了两个属性，在类上加上了@Data，从左面的结构图上可以看到，已经自动生成了上面提到的方法。 Lombok简介ombok是一个可以通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码的工具，通过使用对应的注解，可以在编译源码的时候生成对应的方法。 官方地址：https://projectlombok.org/ github地址：https://github.com/rzwitserloot/lombok Lombok使用注解介绍 @Getter / @Setter 可以作用在类上和属性上，放在类上，会对所有的非静态(non-static)属性生成Getter/Setter方法，放在属性上，会对该属性生成Getter/Setter方法。并可以指定Getter/Setter方法的访问级别。 @EqualsAndHashCode 默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。 @ToString 生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。 @NoArgsConstructor, @RequiredArgsConstructor and @AllArgsConstructor 无参构造器、部分参数构造器、全参构造器，当我们需要重载多个构造器的时候，Lombok就无能为力了。 @Data @ToString, @EqualsAndHashCode, 所有属性的@Getter, 所有non-final属性的@Setter和@RequiredArgsConstructor的组合，通常情况下，我们使用这个注解就足够了。 Lombok原理了解了简单的使用之后，现在应该比较好奇它是如何实现的。整个使用的过程中，只需要使用注解而已，不需要做其它额外的工作，那玄妙之处应该是在注解的解析上。JDK5引入了注解的同时，也提供了两种解析方式。 运行时解析运行时能够解析的注解，必须将@Retention设置为RUNTIME，这样可以通过反射拿到该注解。java.lang.reflect反射包中提供了一个接口AnnotatedElement，该接口定义了获取注解信息的几个方法，Class、Constructor、Field、Method、Package等都实现了该接口，大部分开发者应该都很熟悉这种解析方式。 1234boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass);&lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass);Annotation[] getAnnotations();Annotation[] getDeclaredAnnotations(); 编译时解析编译时解析有两种机制，网上很多文章都把它俩搞混了，分别简单描述一下。 Annotation Processing Toolapt自JDK5产生，JDK7已标记为过期，不推荐使用，JDK8中已彻底删除，自JDK6开始，可以使用Pluggable Annotation Processing API来替换它，apt被替换主要有2点原因： api都在com.sun.mirror非标准包下 没有集成到javac中，需要额外运行 Pluggable Annotation Processing APIJSR 269，自JDK6加入，作为apt的替代方案，它解决了apt的两个问题，javac在执行的时候会调用实现了该API的程序，这样我们就可以对编译器做一些增强，这时javac执行的过程如下： Lombok问题 无法支持多种参数构造器的重载 奇淫巧技，使用会有争议]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapStruct介绍]]></title>
    <url>%2Fjava%2Fjava-MapStruct-1%2F</url>
    <content type="text"><![CDATA[介绍MapStruct在一个成熟可维护的工程中，细分模块后，domian工程最好不要被其他工程依赖，但是实体类一般存于domain之中，这样其他工程想获取实体类数据时就需要在各自工程写model，自定义model可以根据自身业务需要而并不需要映射整个实体属性。mapstruct这个插件就是用来处理domin实体类与model类的属性映射，定义mapper接口，mapstruct就会自动的帮我们实现这个映射接口，避免了麻烦复杂的映射实现。 Github地址：https://github.com/mapstruct/mapstruct/ 使用例子：https://github.com/mapstruct/mapstruct-examples MapStrcut与其它工具对比以及使用说明：http://www.tuicool.com/articles/uiIRjai 如何使用Mapper基本类：BasicObjectMapper，BasicObjectMapper包含了4个基本方法，单个和集合以及反转的单个和集合。 开发中如需要对象转换操作可直接新建interface并继承BasicObjectMapper，并在新建的接口上加上 @Mapper(componentModel = “spring”)， 如果是属性中包含其它类以及该类已经存在Mapper则注解中加上 users = {类名.class}，具体如何使用以及其他各种用法在此不再赘述（本文的重点是看标题，看标题，看标题），google不行可以找度娘， componentModel = “spring”该配置表示生成的实现类默认加上spring @Component注解，使用时可直接通过@Autowire进行注入。 123456789101112131415161718192021package com.ampmind.framework.map;import java.util.List;import org.mapstruct.InheritConfiguration;import org.mapstruct.InheritInverseConfiguration;import org.mapstruct.Mappings;public interface BasicObjectMapper&lt;SOURCE, TARGET&gt; &#123; @Mappings(&#123;&#125;) @InheritConfiguration TARGET to(SOURCE var1); @InheritConfiguration List&lt;TARGET&gt; to(List&lt;SOURCE&gt; var1); @InheritInverseConfiguration SOURCE from(TARGET var1); @InheritInverseConfiguration List&lt;SOURCE&gt; from(List&lt;TARGET&gt; var1);&#125; 下面是两个不同的例子：先贴一下两个Model类 123456789101112131415161718192021222324252627282930package com.ampmind.service.skumng.domain;public class ProductCategory &#123; /** * 类别编码 */ private String categoryCode; /** * 类别名称 */ private String categoryName; public String getCategoryCode() &#123; return categoryCode; &#125; public void setCategoryCode(String categoryCode) &#123; this.categoryCode = categoryCode; &#125; public String getCategoryName() &#123; return categoryName; &#125; public void setCategoryName(String categoryName) &#123; this.categoryName = categoryName; &#125;&#125; CategoryVo 12345678910111213141516171819202122232425262728293031package com.ampmind.service.api.protocol.vo;public class ProductCategory &#123; private String code; private String name; public Integer getParentId() &#123; return parentId; &#125; public void setParentId(Integer parentId) &#123; this.parentId = parentId; &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 1.如何与Spring配合CategoryMapper 1234567891011121314151617package com.ampmind.service.skumng.api.mapper;import com.ampmind.framework.api.base.BasicObjectMapper;import com.ampmind.service.api.protocol.vo.CategoryVo;import com.ampmind.service.domain.ProductCategory;import org.mapstruct.Mapper;import org.mapstruct.Mapping;import org.mapstruct.Mappings;@Mapper(componentModel = "spring")public interface CategoryMapper extends BasicObjectMapper&lt;CategoryVo, ProductCategory&gt; &#123; @Mappings(&#123; @Mapping(source = "code", target = "categoryCode"), @Mapping(source = "name", target = "categoryName") &#125;) ProductCategory to(CategoryVo source);&#125; 上面重写了to方法，注意如果属性名一样可以不用重写。保持接口空的就行，有不一样的需要重写to方法，并在方法上加上 @Mappings注解和子注解spring注入并使用 12345678910111213141516171819@Componentpublic class Test &#123; @Autowired private CategoryMapper categoryMapper; public void test() &#123; CategoryVo vo = new CategoryVo; vo.setCategoryCode("0000"); vo.setCategoryName("属性名称"); ProductCategory pc = categoryMapper.to(vo);// 通过to方法得到 ProductCategory CategoryVo vo1 = categoryMapper.form(pc);// 通过from方法得到CategoryVo，既反转to方法。 List&lt;ProductCategory&gt; pcList = categoryMapper.to(Arrays.asList(vo, vo1));// 通过to方法从集合得到转换后的集合 List&lt;CategoryVo&gt; voList = categoryMapper.from(pcList); // 反转集合 &#125;&#125; 2.如何直接使用CategoryMapper 1234567891011121314151617181920212223package com.ampmind.service.skumng.api.mapper;import com.ampmind.framework.api.base.BasicObjectMapper;import com.ampmind.service.skumng.api.protocol.vo.CategoryVo;import com.ampmind.service.skumng.domain.ProductCategory;import org.mapstruct.Mapper;import org.mapstruct.Mapping;import org.mapstruct.Mappings;import org.mapstruct.factory.Mappers;/** * */@Mapperpublic interface CategoryMapper extends BasicObjectMapper&lt;CategoryVo, ProductCategory&gt; &#123; CategoryMapper MAPPER = Mappers.getMapper(CategoryMapper.class); @Mappings(&#123; @Mapping(source = "code", target = "categoryCode"), @Mapping(source = "name", target = "categoryName") &#125;) ProductCategory to(CategoryVo source);&#125; 直接可以通过main方法进行测试 123456789101112131415public class Test &#123; public static void main(String[] args) &#123; CategoryVo vo = new CategoryVo; vo.setCategoryCode("0000"); vo.setCategoryName("属性名称"); ProductCategory pc = CategoryMapper.MAPPER.to(vo);// 通过to方法得到 ProductCategory CategoryVo vo1 = CategoryMapper.MAPPER.form(pc);// 通过from方法得到CategoryVo，既反转to方法。 List&lt;ProductCategory&gt; pcList = CategoryMapper.MAPPER.to(Arrays.asList(vo, vo1));// 通过to方法从集合得到转换后的集合 List&lt;CategoryVo&gt; voList = CategoryMapper.MAPPER.from(pcList); // 反转集合 &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mapstruct</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaEE PO VO BO DTO POJO DAO 整理总结]]></title>
    <url>%2Fjava%2Fjava-pojo%2F</url>
    <content type="text"><![CDATA[DAO[data access object]数据访问对象 DAO层对开发人员黑盒，由架构师设计封装。在很长一段时间内，我将它理解为对数据库的访问，后面随着项目的积累。发现自己的理解相对狭隘，对数据访问不仅仅指的是对数据库的访问。假如A系统调用B系统的服务获取数据，这时候A系统对B系统访问数据对象的封装也可以称为DAO。 DTO[data transfer object]数据传输对象 假设数据表中存在20个字段，但是在页面展示列表的时候，这20个字段显然都不会用到。我想对其中的5个字段进行展示，而且这5个字段展示的时候，也并不是数据库中他们原有的样子。还需要进行计算、截取、业务代码转名称 …..等等数据传输对象因此而被诞生，一是能提高数据传输的速度，二能隐藏后端表结构。 PO[persistant object]持久层对象 持久对象属性和数据库中的字段是一一对应的，数据库中的一条数据可以理解为一个持久对象。因ORM框架的广泛使用而被引入到 JavaEE 项目设计当中。 BO[bussiness object]业务对象 业务对象顾名思义是在业务处理中抽象出来的对象，里面除了get/set 方法外，也可以有对字段进行业务处理的方法。假设你要对一个班级进行业务处理，其中的学生、教师、甚至是桌椅板凳都是业务对象的组成部分。当然其中的学生、教室….都可以是和数据库对应的PO。 VO[value object]值对象 值对象也可以称做页面对象，如果称做页面对象，那门它所代表的将是整个页面展示层的对象。可以由需要的业务对象进行的换算转换而来。如果称呼他为值对象的话，那门他可以理解为存放业务对象的一个地方。假设锅碗瓢盆分别为对应的业务对象的话，那门整个碗柜就是一个值对象。 POJO[plain ordiary java object] 简单java对象 简单java对象应该是JavaEE世界里面最灵活的对象。在简单系统中，如果从数据库到页面展示都是POJO的话，它可以是DTO。如果从数据库中到业务处理中都是POJO的话，他也可以是BO。同样如果从数据库到整个页面的展示的话，它同样可以是VO。 小结： 各个数据对象之间的转换是相当灵活的，在项目中可以定义上述对象的全部和其中的几种类型，这取决与架构师和需求。在大型项目中，架构师在项目初期的任务除了搭建起整个开发环境以外，定义在系统中流转的数据结构对象同样是重重之重。这项工作需要许多项目的积累和长期对软件开发的思考，多实践，多思考，提供最合适的数据对象解决方法，方能展现架构师的魅力。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>pojo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm使用]]></title>
    <url>%2Fnodejs%2Fnpm-1%2F</url>
    <content type="text"><![CDATA[NPM是随同NodeJS一起安装的包管理工具，能解决NodeJS代码部署上的很多问题，常见的使用场景有以下几种： 允许用户从NPM服务器下载别人编写的第三方包到本地使用。 允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用。 允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。 由于新版的nodejs已经集成了npm，所以之前npm也一并安装好了。同样可以通过输入 “npm -v” 来测试是否成功安装。命令如下，出现版本提示表示安装成功: 12$ npm -v2.3.0 如果你安装的是旧版本的 npm，可以很容易得通过 npm 命令来升级，命令如下： 123$ sudo npm install npm -g/usr/local/bin/npm -&gt; /usr/local/lib/node_modules/npm/bin/npm-cli.jsnpm@2.14.2 /usr/local/lib/node_modules/npm 如果是 Window 系统使用以下命令即可： 1$ npm install npm -g 使用 npm 命令安装模块npm 安装 Node.js 模块语法格式如下： 1$ npm install &lt;Module Name&gt; 以下实例，我们使用 npm 命令安装常用的 Node.js web框架模块 express: 1$ npm install express 安装好之后，express 包就放在了工程目录下的 node_modules 目录中，因此在代码中只需要通过 require(‘express’) 的方式就好，无需指定第三方包路径。 1var express = require('express'); 全局安装与本地安装npm 的包安装分为本地安装（local）、全局安装（global）两种，从敲的命令行来看，差别只是有没有-g而已，比如 12$ npm install express # 本地安装$ npm install express -g # 全局安装 如果出现以下错误： 1npm err! Error: connect ECONNREFUSED 127.0.0.1:8087 解决办法为： 1$ npm config set proxy null 本地安装 将安装包放在 ./node_modules 下（运行 npm 命令时所在的目录），如果没有 node_modules 目录，会在当前执行 npm 命令的目录下生成 node_modules 目录。 可以通过 require() 来引入本地安装的包。 全局安装 将安装包放在 /usr/local 下或者你 node 的安装目录。 可以直接在命令行里使用。 如果你希望具备两者功能，则需要在两个地方安装它或使用 npm link。接下来我们使用全局方式安装 express 1$ npm install express -g 查看安装信息你可以使用以下命令来查看所有全局安装的模块： 1$ npm list -g 如果要查看某个模块的版本号，可以使用命令如下： 1$ npm list grunt 使用 package.jsonpackage.json 位于模块的目录下，用于定义包的属性。接下来让我们来看下 express 包的 package.json 文件，位于 node_modules/express/package.json 内容： 12345678910111213141516171819202122232425262728293031&#123; "name": "hexo-site", "version": "0.0.0", "private": true, "hexo": &#123; "version": "3.4.4" &#125;, "dependencies": &#123; "hexo": "^3.2.0", "hexo-deployer-git": "^0.3.1", "hexo-generator-archive": "^0.1.4", "hexo-generator-category": "^0.1.3", "hexo-generator-index": "^0.2.0", "hexo-generator-tag": "^0.2.0", "hexo-renderer-ejs": "^0.3.0", "hexo-renderer-marked": "^0.3.0", "hexo-renderer-stylus": "^0.3.1", "hexo-server": "^0.2.0" &#125;, "devDependencies": &#123; "gulp": "^3.9.1", "gulp-htmlclean": "^2.7.16", "gulp-htmlmin": "^4.0.0", "gulp-minify-css": "^1.2.4", "gulp-uglify": "^3.0.0", "hexo-admin": "^2.3.0", "hexo-generator-searchdb": "^1.0.8", "hexo-wordcount": "^3.0.2" &#125;&#125;` Package.json 属性说明 name - 包名。 version - 包的版本号。 description - 包的描述。 homepage - 包的官网 url 。 author - 包的作者姓名。 contributors - 包的其他贡献者姓名。 dependencies - 依赖包列表。如果依赖包没有安装，npm 会自动将依赖包安装在 node_module 目录下。 repository - 包代码存放的地方的类型，可以是 git 或 svn，git 可在 Github 上。 main - main 字段指定了程序的主入口文件，require(‘moduleName’) 就会加载这个文件。这个字段的默认值是模块根目录下面的 index.js。 keywords - 关键字 卸载模块我们可以使用以下命令来卸载 Node.js 模块。 1$ npm uninstall express 卸载后，你可以到 /node_modules/ 目录下查看包是否还存在，或者使用以下命令查看： 1$ npm ls 更新模块我们可以使用以下命令更新模块： 1$ npm update express 搜索模块使用以下来搜索模块： 1$ npm search express 使用淘宝 NPM 镜像大家都知道国内直接使用 npm 的官方镜像是非常慢的，这里推荐使用淘宝 NPM 镜像。 淘宝 NPM 镜像是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步。 你可以使用淘宝定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org 安装不创建bin链接1$ npm install --no-bin-links 编译并不创建bin链接1$ npm rebuild node-sass --no-bin-links]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VirtualBox建立软链接]]></title>
    <url>%2FVirtualBox%2FVirtualBox-1%2F</url>
    <content type="text"><![CDATA[VirtualBox共享目录，建立软链接 关闭 VirtualBox。 将VirtualBox安装目录的路径加入系统环境变量PATH中。 打开命令行窗口，执行如下命令： 12VBoxManage setextradata &#123;YOURVMNAME&#125;VBoxInternal2/SharedFoldersEnableSymlinksCreate/&#123;YOURSHAREFOLDERNAME&#125; 1 参数说明YOURVMNAME：为虚拟机中ubuntu系统的名YOURSHAREFOLDERNAME：为共享的目录名称 “以管理者身份运行” VirtualBox 即可！]]></content>
      <categories>
        <category>VirtualBox</category>
      </categories>
      <tags>
        <tag>VirtualBox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9个常用iptables配置实例]]></title>
    <url>%2Flinux%2Flinux-shell-iptabls-2%2F</url>
    <content type="text"><![CDATA[iptables命令可用于配置Linux的包过滤规则，常用于实现防火墙、NAT。咋一看iptables的配置很复杂，掌握规律后，其实用iptables完成指定任务并不难，下面我们通过具体实例，学习iptables的详细用法。 删除已有规则 在新设定iptables规则时，我们一般先确保旧规则被清除，用以下命令清除旧规则 12$ iptables -F(or iptables --flush) 设置chain策略 对于filter table，默认的chain策略为ACCEPT，我们可以通过以下命令修改chain的策略 123$ iptables -P INPUT DROP$ iptables -P FORWARD DROP$ iptables -P OUTPUT DROP 以上命令配置将接收、转发和发出包均丢弃，施行比较严格的包管理。由于接收和发包均被设置为丢弃，当进一步配置其他规则的时候，需要注意针对INPUT和OUTPUT分别配置。当然，如果信任本机器往外发包，以上第三条规则可不必配置。 屏蔽指定ip 有时候我们发现某个ip不停的往服务器发包，这时我们可以使用以下命令，将指定ip发来的包丢弃 12$ BLOCK_THIS_IP="x.x.x.x"$ iptables -A INPUT -i eth0 -p tcp -s "$BLOCK_THIS_IP" -j DROP 以上命令设置将由x.x.x.x ip发往eth0网口的tcp包丢弃 配置服务项 利用iptables，我们可以对日常用到的服务项进行安全管理，比如设定只能通过指定网段、由指定网口通过SSH连接本机 12$ iptables -A INPUT -i eth0 -p tcp -s 192.168.100.0/24 --dport 22 -m state --state NEW,ESTABLESHED -j ACCEPT$ iptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT 若要支持由本机通过SSH连接其他机器，由于在本机端口建立连接，因而还需要设置以下规则 12$ iptables -A INPUT -i eth0 -p tcp -s 192.168.100.0/24 --dport 22 -m state --state ESTABLESHED -j ACCEPT$ iptables -A OUTPUT -o eth0 -p tcp --sport 22 -m state --state NEW,ESTABLISHED -j ACCEPT 类似的，对于HTTP/HTTPS(80/443)、pop3(110)、rsync(873)、MySQL(3306)等基于tcp连接的服务，也可以参照上述命令配置。 对于基于udp的dns服务，使用以下命令开启端口服务 12$ iptables -A OUTPUT -p udp -o eth0 --dport 53 -j ACCEPT$ iptables -A INPUT -p udp -i eth0 --sport 53 -j ACCEPT 网口转发配置 对于用作防火墙或网关的服务器，一个网口连接到公网，其他网口的包转发到该网口实现内网向公网通信，假设eth0连接内网，eth1连接公网，配置规则如下 1$ iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT 端口转发配置 对于端口，我们也可以运用iptables完成转发配置 1$ iptables -t nat -A PREROUTING -p tcp -d 192.168.102.37 --dport 422 -j DNAT --to 192.168.102.37:22 以上命令将422端口的包转发到22端口，因而通过422端口也可进行SSH连接，当然对于422端口，我们也需要像以上“4.配置服务项”一节一样，配置其支持连接建立的规则。 DoS攻击防范 利用扩展模块limit，我们还可以配置iptables规则，实现DoS攻击防范 1$ iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT –litmit 25/minute 指示每分钟限制最大连接数为25–litmit-burst 100 指示当总连接数超过100时，启动 litmit/minute 限制 配置web流量均衡 我们可以将一台服务器作为前端服务器，利用iptables进行流量分发，配置方法如下 123$ iptables -A PREROUTING -i eth0 -p tcp --dport 80 -m state --state NEW -m nth --counter 0 --every 3 --packet 0 -j DNAT --to-destination 192.168.1.101:80$ iptables -A PREROUTING -i eth0 -p tcp --dport 80 -m state --state NEW -m nth --counter 0 --every 3 --packet 0 -j DNAT --to-destination 192.168.1.102:80$ iptables -A PREROUTING -i eth0 -p tcp --dport 80 -m state --state NEW -m nth --counter 0 --every 3 --packet 0 -j DNAT --to-destination 192.168.1.103:80 以上配置规则用到nth扩展模块，将80端口的流量均衡到三台服务器 将丢弃包情况记入日志 使用LOG目标和syslog服务，我们可以记录某协议某端口下的收发包情况。拿记录丢包情况举例，可以通过以下方式实现。 首先自定义一个chain 1$ iptables -N LOGGING 其次将所有接收包导入LOGGING chain中 1$ iptables -A INPUT -j LOGGING 然后设置日志前缀、日志级别 1$ iptables -A LOGGING -m limit --limit 2/min -j LOG --log-prefix "IPTables Packet Dropped: " --log-level 7 最后将包倒向DROP，将包丢弃 1$ iptables -A LOGGING -j DROP 另可以配置syslog.conf文件，指定iptables的日志输出]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TC基于CBQ队列的流量管理范例]]></title>
    <url>%2Flinux%2Flinux-shell-tc-1%2F</url>
    <content type="text"><![CDATA[简介参考了TC的很多文档，自己也整理了一篇配置记录。在实际使用过程中效果还不错，在此分享给大家以备参考。环境：局域网规模不是很大40多台机器。 NAT共享上网（内网：eth0 外网：eth2）CBQ是通过硬件的闲置时间来计算队列，硬件不同，效果也不同，对于比较大的网络使用HTB比较好。以下限制上传和下载的方法可以写成脚本，通过mrtg发现流量的异常情况，然后通过ntop查处是谁在干坏事，最后用写好的tc脚本限制他的流量，避免影响其他人的网络使用。 示例针对网络物理设备绑定一个CBQ队列 1$ tc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64 将一个cbq队列绑定到网络物理设备eth0上，其编号为1:0；网络物理设备eth0的实际带宽为10Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。 在该队列上建立分类 1$ tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 1Mbit 创建根分类1:1；分配带宽为10Mbit，优先级别为1。该队列的最大可用带宽为10Mbit，实际分配的带宽为10Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为1Mbit。 创建子分类 创建分类1:2，其父分类为1:1，分配带宽为64Kbit，优先级别为8。该队列的最大可用带宽为10Mbit，实际分配的带宽为64Kbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，且不可借用未使用带宽。$ tc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 64Kbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 100Kbit bounded 创建分类1:3，其父分类为1:1，分配带宽为64Kbit，优先级别为9。该队列的最大可用带宽为10Mbit，实际分配的带宽为64Kbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为9，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，且不可借用未使用带宽。$ tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 64Kbit maxburst 20 allot 1514 prio 9 avpkt 1000 cell 8 weight 100Kbit bounded 在子分类地下创建队列，使用sfq随机公平队列 12$ tc qdisc add dev eth0 parent 1:2 sfq quantum 1514b perturb 15$ tc qdisc add dev eth0 parent 1:3 sfq quantum 1514b perturb 15 在分类底下，创建队列，使用sfq随即公平队列 为每一分类建立一个基于路由的过滤 12$ tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip dst 192.111.1.116 flowid 1:2$ tc filter add dev eth0 parent 1:0 protocol ip prio 1 u32 match ip dst 192.111.1.66 flowid 1:3 限制各ip地址的下载带宽，使用u32过滤器，对目的地址进行分类，对应已经创建的队列需要添加新的被限制ip的下载带宽，需要先要创建新的分类(比如1:4),然后根据新的分类创建新的sfq队列，最后使用u32过滤器对目的地址进行带宽限制。需要对几个ip限制下载带宽，就需要创建几个分类、队列、过滤器 限制上传 将一个cbq队列绑定到网络物理设备eth2上，其编号为2:0；网络物理设备eth2的实际带宽为2Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。 1$ tc qdisc add dev eth2 root handle 2: cbq bandwidth 2Mbit avpkt 1000 cell 8 mpu 64 创建根分类2:1；分配带宽为2Mbit，优先级别为1。该队列的最大可用带宽为2Mbit，实际分配的带宽2Mbit， 可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均 大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为200Kbit。 1$ tc class add dev eth2 parent 2:0 classid 2:1 cbq bandwidth 2Mbit rate 2Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 200Kbit 创建分类2:2，其父分类为2:1，分配带宽为64Kbit，优先级别为8。该队列的最大可用带宽为2Mbit，实际分配的带宽为64Kbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，且不可借用未使用带宽。 1$ tc class add dev eth2 parent 2:1 classid 2:2 cbq bandwidth 2Mbit rate 64Kbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 200Kbit bounded 在分类底下，创建队列，使用sfq随即公平队列 1$ tc qdisc add dev eth2 parent 2:2 sfq quantum 1514b perturb 15 应用路由分类器到cbq队列的根，过滤协议为ip，优先级为100 1$ tc filter add dev eth2 parent 2:0 protocol ip prio 1 handle 2 fw classid 2:2 给数据包打标签,可以通过RETURN方法避免遍历所有的规则，加快处理速度 12$ iptables –t mangle –A PREROUTING –i eth0 –s 192.111.1.xxx –j MARK --set-mark 2$ iptables –t mangle –A PREROUTING –i eth0 –s 192.111.1.xxx –j RETURN nat模式 1$ iptables -t nat -A POSTROUTING -s 192.111.1.0/24 -o eth2 -j SNAT --to 外网IP 需要添加新的被限制ip的上传带宽，需要先要创建新的分类(比如2:3),然后根据新的分类创建新的sfq队列，最后使用路由过滤器，过滤协议为ip，给原地址是需要限制的ip地址来的数据包打标记。需要对几个ip限制下载带宽，就需要创建几个分类、队列、路由过滤器、iptable的mangle表的PREROUTING链 另外还有其他的过滤器比如 1$ tc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2 ip route add 192.111.1.24 dev eth0 via 192.111.1.4 realm 2 维护 主要包括对队列、分类、过滤器和路由的增添、修改和删除。 增添动作一般依照”队列-&gt;分类-&gt;过滤器-&gt;路由”的顺序进行；修改动作则没有什么要求；删除则依照”路由-&gt;过滤器-&gt;分类-&gt;队列”的顺序进行。 简单显示指定设备的队列状况 1$ tc qdisc ls dev eth0 详细显示指定设备的队列状况 1$ tc –s qdisc ls dev eth0 简单显示指定设备的分类状况 1$ tc class ls dev eth0 详细显示指定设备的分类状况 1$ tc –s class ls dev eth0 显示过滤器的状况 1$ tc –s filter ls dev eth0 队列的维护 一般对于一台流量控制器来说，出厂时针对每个以太网卡均已配置好一个队列了，通常情况下对队列无需进行增添、修改和删除动作了。 分类的维护 增添动作通过tc class add命令实现。 修改动作通过tc class change命令实现，如下所示： 1$ tc class change dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 64Kbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 100Kbit bounded 对于bounded命令应慎用，一旦添加后就进行修改，只可通过删除后再添加来实现。 过滤器的维护 增添动作通过tc filter add命令实现。 修改动作通过tc filter change命令实现，如下所示： 1$ tc filter change dev eth0 parent 1:0 protocol ip prio 1 u32 match ip dst 192.111.1.116 flowid 1:2 删除动作通过tc filter del命令实现，如下所示： 1$ tc filter del dev eth0 parent 1:0 protocol ip prio 1 u32 match ip dst 192.111.1.116 flowid 1:]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>tc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables之nat表应用——IP与端口的映射]]></title>
    <url>%2Flinux%2Flinux-shell-iptables-1%2F</url>
    <content type="text"><![CDATA[需求 将192.168.3.195：80 映射到192.168.3.193：80，即访问192.168.3.195：80，得到192.168.3.193：80的结果，实现linux的路由。 实现 123456789101112131415161718192021#!/bin/bash#打开转发功能echo "1" &gt; /proc/sys/net/ipv4/ip_forward /sbin/iptables -F -t filter#清空iptables/sbin/iptables -F -t nat #去192.168.3.193的一条路/sbin/iptables -t nat -A PREROUTING -d 192.168.3.195 -p tcp --dport 80 -j DNAT --to-destination 192.168.3.193:80 #返回的时候的一条路，ip传输要有去有回才能连通 /sbin/iptables -t nat -A POSTROUTING -s 192.168.3.0/24 -o eth0 -j SNAT --to 192.168.3.195 #用2网段访问的时候的回路/sbin/iptables -t nat -A POSTROUTING -s 192.168.2.0/24 -o eth0 -j SNAT --to 192.168.3.195 #用0网段访问的时候的回路/sbin/iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j SNAT --to 192.168.3.195 回路的那一条，或者只用下面这一句：iptables -t nat -A POSTROUTING -s 0.0.0.0/0 -o eth0 -j SNAT --to 192.168.3.195或者iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to 192.168.3.195把193上的80端口打开 测试 在192.168.3.195上访问 192.168.3.195：80看到 195的apache主页，因为在本机上访问，没有走PREROUTING这条链。在其他主机上访问192.168.3.195：80 返回193的apache主页，路线为PREROUTING–&gt;FORWARD–&gt;PSOTROUTING.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iptables命令]]></title>
    <url>%2Flinux%2Flinux-shell-iptables%2F</url>
    <content type="text"><![CDATA[简介iptables命令是Linux上常用的防火墙软件，是netfilter项目的一部分。可以直接配置，也可以通过许多前端和图形界面配置。 参数说明12345678910111213141516-t&lt;表&gt;：指定要操纵的表；-A：向规则链中添加条目；-D：从规则链中删除条目；-i：向规则链中插入条目；-R：替换规则链中的条目；-L：显示规则链中已有的条目；-F：清楚规则链中已有的条目；-Z：清空规则链中的数据包计算器和字节计数器；-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；-h：显示帮助信息；-p：指定要匹配的数据包协议类型；-s：指定要匹配的数据包源ip地址；-j&lt;目标&gt;：指定要跳转的目标；-i&lt;网络接口&gt;：指定数据包进入本机的网络接口；-o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口。 命令格式iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 表名包括 1234raw：高级功能，如：网址过滤。mangle：数据包修改（QOS），用于实现服务质量。net：地址转换，用于网关路由器。filter：包过滤，用于防火墙规则。 规则链名包括 12345INPUT链：处理输入数据包。OUTPUT链：处理输出数据包。PORWARD链：处理转发数据包。PREROUTING链：用于目标地址转换（DNAT）。POSTOUTING链：用于源地址转换（SNAT）。 动作包括 1234567accept：接收数据包。DROP：丢弃数据包。REDIRECT：重定向、映射、透明代理。SNAT：源地址转换。DNAT：目标地址转换。MASQUERADE：IP伪装（NAT），用于ADSL。LOG：日志记录。 示例清除已有iptables规则123$ iptables -F$ iptables -X$ iptables -Z 开放指定的端口123456789$ iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许本地回环接口(即运行本机访问本机)$ iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许已建立的或相关连的通行$ iptables -A OUTPUT -j ACCEPT #允许所有本机向外的访问$ iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问22端口$ iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问80端口$ iptables -A INPUT -p tcp --dport 21 -j ACCEPT #允许ftp服务的21端口$ iptables -A INPUT -p tcp --dport 20 -j ACCEPT #允许FTP服务的20端口$ iptables -A INPUT -j reject #禁止其他未允许的规则访问$ iptables -A FORWARD -j REJECT #禁止其他未允许的规则访问 屏蔽IP1234$ iptables -I INPUT -s 123.45.6.7 -j DROP #屏蔽单个IP的命令$ iptables -I INPUT -s 123.0.0.0/8 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令$ iptables -I INPUT -s 124.45.0.0/16 -j DROP #封IP段即从123.45.0.1到123.45.255.254的命令$ iptables -I INPUT -s 123.45.6.0/24 -j DROP #封IP段即从123.45.6.1到123.45.6.254的命令是 查看已添加的iptables规则123456789101112131415$ iptables -L -n -vChain INPUT (policy DROP 48106 packets, 2690K bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 191K 90M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:221499K 133M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:804364K 6351M ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 6256 327K ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 3382K packets, 1819M bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- * lo 0.0.0.0/0 0.0.0.0/0 删除已添加的iptables规则 将所有iptables以序号标记显示，执行 1$ iptables -L -n --line-numbers 比如要删除INPUT里序号为8的规则，执行 1$ iptables -D INPUT 8]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell /bin/bash^M: bad interpreter错误解决]]></title>
    <url>%2Flinux%2Flinux-error-bash-1%2F</url>
    <content type="text"><![CDATA[错误原因之一很有可能是你的脚本文件是DOS格式的, 即每一行的行尾以\r\n来标识, 其ASCII码分别是0x0D, 0x0A.可以有很多种办法看这个文件是DOS格式的还是UNIX格式的, 还是MAC格式的。 vi filename然后用命令:set ff?可以看到dos或unix的字样. 如果的确是dos格式的, 那么你可以用set ff=unix把它强制为unix格式的, 然后存盘退出. 再运行一遍看. 用joe filename如果是DOS格式的, 那么行尾会有很多绿色的^M字样出现. 你也可以用上述办法把它转为UNIX格式的. 用od -t x1 filename如果你看到有0d 0a 这样的字符, 那么它是dos格式的, 如果只有0a而没有0d, 那么它是UNIX格式的, 同样可以用上述方法把它转为UNIX格式的. 转换不同平台的文本文件格式可以用 unix2dos或dos2unix这两个小程序来做. 很简单. 在djgpp中这两个程序的名字叫dtou和utod, u代表unix, d代表dos 也可以用sed 这样的工具来做: 12$ sed 's/^M//' filename &gt; tmp_filename$ mv -f tmp_filename filename 来做说明:^M并不是按键shift + 6产生的^和字母M, 它是一个字符, 其ASCII是0x0D, 生成它的办法是先按CTRL+V, 然后再回车(或CTRL+M)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tcpdump命令]]></title>
    <url>%2Flinux%2Flinux-shell-tcpdump%2F</url>
    <content type="text"><![CDATA[简介用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。 参数说明 使用格式 $ tcpdump [ -DenNqvX ] [ -c count ] [ -F file ] [ -i interface ] [ -r file ] [ -s snaplen ] [ -wfile ] [ expression ] 抓包选项 12345678910111213-c：指定要抓取的包数量。注意，是最终要获取这么多个包。例如，指定"-c 10"将获取10个包，但可能已经 处理了100个包，只不过只有10个包是满足条件的包。 -i interface：指定tcpdump需要监听的接口。若未指定该选项，将从系统接口列表中搜寻编号最小的已配置好的接口(不包括loopback接口，要抓取loopback接口使用tcpdump -i lo)，一旦找到第一个符合条件的接口，搜寻马上结束。可以使用'any'关键字表示所有网络接口。 -n：对地址以数字方式显式，否则显式为主机名，也就是说-n选项不做主机名解析。-nn：除了-n的作用外，还把端口显示为数值，否则显示端口服务名。-N：不打印出host的域名部分。例如tcpdump将会打印'nic'而不是'nic.ddn.mil'。-P：指定要抓取的包是流入还是流出的包。可以给定的值为"in"、"out"和"inout"，默认为"inout"。-s len：设置tcpdump的数据包抓取长度为len，如果不设置默认将会是65535字节。对于要抓取的数据包较大时，长度设置不够可能会产生包截断，若出现包截断，输出行中会出现"[|proto]"的标志(proto实际会显示为协议名)。但是抓取len越长，包的处理时间越长，并且会减少tcpdump可缓存的数据包的数量，从而会导致数据包的丢失，所以在能抓取我们想要的包的前提下，抓取长度越小越好。 输出选项 1234567-e：输出的每行中都将包括数据链路层头部信息，例如源MAC和目标MAC。-q：快速打印输出。即打印很少的协议相关信息，从而输出行都比较简短。-X：输出包的头部数据，会以16进制和ASCII两种方式同时输出。-XX：输出包的头部数据，会以16进制和ASCII两种方式同时输出，更详细。-v：当分析和打印的时候，产生详细的输出。-vv：产生比-v更详细的输出。-vvv：产生比-vv更详细的输出。 其他功能性选项 12345-D：列出可用于抓包的接口。将会列出接口的数值编号和接口名，它们都可以用于"-i"后。-F：从文件中读取抓包的表达式。若使用该选项，则命令行中给定的其他表达式都将失效。-w：将抓包数据输出到文件中而不是标准输出。可以同时配合"-G time"选项使得输出文件每time秒就自动切换到另一个文件。可通过"-r"选项载入这些文件以进行分析和打印。-r：从给定的数据包文件中读取数据。使用"-"表示从标准输入中读取。 示例 监视指定网络接口的数据包 1$ tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，如eth0。 监视指定主机的数据包，例如所有进入或离开longshuai的数据包 1$ tcpdump host longshuai 打印helios&lt;–&gt;hot或helios&lt;–&gt;ace之间通信的数据包 1$ tcpdump host helios and \( hot or ace \) 打印ace与任何其他主机之间通信的IP数据包,但不包括与helios之间的数据包 1$ tcpdump ip host ace and not helios 截获主机hostname发送的所有数据 1$ tcpdump src host hostname 监视所有发送到主机hostname的数据包 1$ tcpdump dst host hostname 监视指定主机和端口的数据包 1$ tcpdump tcp port 22 and host hostname 对本机的udp 123端口进行监视(123为ntp的服务端口) 1$ tcpdump udp port 123 监视指定网络的数据包，如本机与192.168网段通信的数据包，”-c 10”表示只抓取10个包 1$ tcpdump -c 10 net 192.168 打印所有通过网关snup的ftp数据包(注意,表达式被单引号括起来了,这可以防止shell对其中的括号进行错误解析) 1$ tcpdump 'gateway snup and (port ftp or ftp-data)' 抓取ping包 1$ tcpdump -c 5 -nn -i eth0 icmp 如果明确要抓取主机为192.168.100.70对本机的ping，则使用and操作符。 1$ tcpdump -c 5 -nn -i eth0 icmp and src 192.168.100.62 注意不能直接写icmp src 192.168.100.70，因为icmp协议不支持直接应用host这个type。 抓取到本机22端口包 1$ tcpdump -c 10 -nn -i eth0 tcp dst port 22 解析包数据 1$ tcpdump -c 2 -q -XX -vvv -nn -i eth0 tcp dst port 22]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DATE命令]]></title>
    <url>%2Flinux%2Flinux-shell-date%2F</url>
    <content type="text"><![CDATA[简介很多shell脚本里面需要打印不同格式的时间或日期，以及要根据时间和日期执行操作。延时通常用于脚本执行过程中提供一段等待的时间。日期可以以多种格式去打印，也可以使用命令设置固定的格式。在类UNIX系统中，日期被存储为一个整数，其大小为自世界标准时间（UTC）1970年1月1日0时0分0秒起流逝的秒数。 参数说明12345-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；-s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号；-u：显示GMT；--help：在线帮助；--version：显示版本信息。 格式列表1234567891011121314151617181920212223242526272829%n : 下一行%t : 跳格%H : 小时(00..23)%I : 小时(01..12)%k : 小时(0..23)%l : 小时(1..12)%M : 分钟(00..59)%p : 显示本地 AM 或 PM%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M)%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数%S : 秒(00..61)%T : 直接显示时间 (24 小时制)%X : 相当于 %H:%M:%S%Z : 显示时区 %a : 星期几 (Sun..Sat)%A : 星期几 (Sunday..Saturday)%b : 月份 (Jan..Dec)%B : 月份 (January..December)%c : 直接显示日期与时间%d : 日 (01..31)%D : 直接显示日期 (mm/dd/yy)%h : 同 %b%j : 一年中的第几天 (001..366)%m : 月份 (01..12)%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形)%w : 一周中的第几天 (0..6)%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形)%x : 直接显示日期 (mm/dd/yy)%y : 年份的最后两位数字 (00.99)%Y : 完整年份 (0000..9999) 示例设置时间1234567date -s //设置当前时间，只有root权限才能设置，其他只能查看。date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00date -s 01:01:01 //设置具体时间，不会对日期做更改date -s “01:01:01 2008-05-23″ //这样可以设置全部时间date -s “01:01:01 20080523″ //这样可以设置全部时间date -s “2008-05-23 01:01:01″ //这样可以设置全部时间date -s “20080523 01:01:01″ //这样可以设置全部时间 时间加减1234567date +%Y%m%d //显示现在天年月日date +%Y%m%d --date="+1 day" //显示后一天的日期date +%Y%m%d --date="-1 day" //显示前一天的日期date +%Y%m%d --date="-1 month" //显示上一月的日期date +%Y%m%d --date="+1 month" //显示下一月的日期date +%Y%m%d --date="-1 year" //显示前一年的日期date +%Y%m%d --date="+1 year" //显示下一年的日期]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>date</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hwclock命令]]></title>
    <url>%2Flinux%2Flinux-shell-hwclock%2F</url>
    <content type="text"><![CDATA[简介hwclock命令是一个硬件时钟访问工具，它可以显示当前时间、设置硬件时钟的时间和设置硬件时钟为系统时间，也可设置系统时间为硬件时钟的时间。 在Linux中有硬件时钟与系统时钟等两种时钟。硬件时钟是指主机板上的时钟设备，也就是通常可在BIOS画面设定的时钟。系统时钟则是指kernel中的时钟。当Linux启动时，系统时钟会去读取硬件时钟的设定，之后系统时钟即独立运作。所有Linux相关指令与函数都是读取系统时钟的设定。 参数说明12345678910--adjust：hwclock每次更改硬件时钟时，都会记录在/etc/adjtime文件中。使用--adjust参数，可使hwclock根据先前的记录来估算硬件时钟的偏差，并用来校正目前的硬件时钟；--debug：显示hwclock执行时详细的信息；--directisa：hwclock预设从/dev/rtc设备来存取硬件时钟。若无法存取时，可用此参数直接以I/O指令来存取硬件时钟；--hctosys：将系统时钟调整为与目前的硬件时钟一致；--set --date=&lt;日期与时间&gt;：设定硬件时钟；--show：显示硬件时钟的时间与日期；--systohc：将硬件时钟调整为与目前的系统时钟一致；--test：仅测试程序，而不会实际更改硬件时钟；--utc：若要使用格林威治时间，请加入此参数，hwclock会执行转换的工作；--version：显示版本信息。 示例设置硬件时间要依赖于操作系统时间12$ hwclock –systohc$ hwclock --systohc –-utc 查看当前的硬件日期和时间1$ hwclock 设置硬件时间1$ hwclock -w 查看clock文件，确认是否设置了UTC12$ cat /etc/default/rcS UTC=yes]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>hwclock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftpd安装]]></title>
    <url>%2Flinux%2Flinux-software-vsftpd%2F</url>
    <content type="text"><![CDATA[准备工作 linux系统centos7 vsftpd软件 yum安装 执行步骤安装vsftpd服务器 1$ yum install vsftpd 安装一个加密工具 1$ yum install libdb-utils.x86_64 修改配置VSFTP 1$ vi /etc/vsftpd/vsftpd.conf 配置文件参数说明 anonymous_enable=NO #设定不允许匿名访问 local_enable=YES #设定本地用户可以访问。注：如使用虚拟宿主用户，在该项目设定为NO的情况下所有虚拟用户将无法访问。 chroot_list_enable=YES #使用户不能离开主目录 ascii_upload_enable=YES #允许使用ASCII模式上传 ascii_download_enable=YES #设定支持ASCII模式的上传和下载功能。 pam_service_name=vsftpd #PAM认证文件名。PAM将根据/etc/pam.d/vsftpd进行认证 guest_enable=YES #设定启用虚拟用户功能。 guest_username=ftp #指定虚拟用户的宿主用户。-RHEL/CentOS中已经有内置的ftp用户了 user_config_dir=/etc/vsftpd/vuser_conf #设定虚拟用户个人vsftp的RHEL/CentOS FTP服务文件存放路 径。 listen=YES # 只监听ipv4的地址 xferlog_file=/var/log/xferlog # 日志文件的路径 listen_port=1315 #FTP端口 pasv_enable=YES #开启被动模式 pasv_min_port=10060 pasv_max_port=10070 创建chroot list，将ftp用户加入其中 12$ touch /etc/vsftpd/chroot_list$ echo ftp &gt;&gt; /etc/vsftpd/chroot_list 安装Berkeley DB工具 1$ yum install db4 db4-utils 创建用户密码文本 1$ touch /etc/vsftpd/vuser_passwd.txt 生成虚拟用户认证的db文件 12$ db_load -T -t hash -f /etc/vsftpd/vuser_passwd.txt /etc/vsftpd/vuser_passwd.db$ chmod 600 /etc/vsftpd/vuser_passwd.db 编辑认证文件 1$ vi /etc/pam.d/vsftpd 把前面的注释去掉，然后加上以下几条 系统为32位： auth required pam_userdb.so db=/etc/vsftpd/vuser_passwd account required pam_userdb.so db=/etc/vsftpd/vuser_passwd 系统为64位：auth required /lib64/security/pam_userdb.sodb=/etc/vsftpd/vuser_passwd account required/lib64/security/pam_userdb.so db=/etc/vsftpd/vuser_passwd 修改VSFTPD端口 执行vi /etc/services，将其中的 ftp 21/tcp 改为 ftp 1315/tcp , ftp21/udp改为 ftp 1315/udp 重启动vsftp服务 1$ service vsftpd restart]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>software</tag>
        <tag>vsftpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GREP命令]]></title>
    <url>%2Flinux%2Flinux-shell-grep%2F</url>
    <content type="text"><![CDATA[简介grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 参数说明12345678910111213141516171819202122232425-a 不要忽略二进制数据。-A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。-b 在显示符合范本样式的那一行之外，并显示该行之前的内容。-c 计算符合范本样式的列数。-C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。-d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。-e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。-E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。-f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。-F 将范本样式视为固定字符串的列表。-G 将范本样式视为普通的表示法来使用。-h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。-H 在显示符合范本样式的那一列之前，标示该列的文件名称。-i 忽略字符大小写的差别。-l 列出文件内容符合指定的范本样式的文件名称。-L 列出文件内容不符合指定的范本样式的文件名称。-n 在显示符合范本样式的那一列之前，标示出该列的编号。-q 不显示任何信息。-R/-r 此参数的效果和指定“-d recurse”参数相同。-s 不显示错误信息。-v 反转查找。-w 只显示全字符合的列。-x 只显示全列符合的列。-y 此参数效果跟“-i”相同。-o 只输出文件中匹配到的部分。 示例 在文件中搜索一个单词，命令会返回一个包含“match_pattern”的文本行： 12$ grep match_pattern file_name$ grep "match_pattern" file_name 在多个文件中查找 1$ grep "match_pattern" file_1 file_2 file_3 ... 输出除之外的所有行 -v 选项 1$ grep -v "match_pattern" file_name 标记匹配颜色 –color=auto 选项 1$ grep "match_pattern" file_name --color=auto 使用正则表达式 -E 选项 12$ grep -E "[1-9]+"$ egrep "[1-9]+" 只输出文件中匹配到的部分 -o 选项 12$ echo this is a test line. | grep -o -E "[a-z]+\."$ echo this is a test line. | egrep -o "[a-z]+\." 统计文件或者文本中包含匹配字符串的行数 -c 选项 1$ grep -c "text" file_name 输出包含匹配字符串的行数 -n 选项 123456$ grep "text" -n file_name或$ cat file_name | grep "text" -n#多个文件$ grep "text" -n file_1 file_2 打印样式匹配所位于的字符或字节偏移 1234$ echo gun is not unix | grep -b -o "not"7:not#一行中字符串的字符便宜是从该行的第一个字符开始计算，起始值为0。选项 -b -o 一般总是配合使用。 搜索多个文件并查找匹配文本在哪些文件中 1$ grep -l "text" file1 file2 file3... 在多级目录中对文本进行递归搜索 12$ grep "text" . -r -n# .表示当前目录。 忽略匹配样式中的字符大小写 1$ echo "hello world" | grep -i "HELLO" 选项 -e 制动多个匹配样式 12345$ echo this is a text line | grep -e "is" -e "line" -o#也可以使用-f选项来匹配多个样式，在样式文件中逐行写出需要匹配的字符。$ echo aaa bbb ccc ddd eee | grep -f patfile -o 在grep搜索结果中包括或者排除指定文件 12345678#只在目录中所有的.php和.html文件中递归搜索字符"main()"$ grep "main()" . -r --include *.&#123;php,html&#125;#在搜索结果中排除所有README文件$ grep "main()" . -r --exclude "README"#在搜索结果中排除filelist文件列表里的文件$ grep "main()" . -r --exclude-from filelist 使用0值字节后缀的grep与xargs 12345678#测试文件：$ echo "aaa" &gt; file1$ echo "bbb" &gt; file2$ echo "aaa" &gt; file3$ grep "aaa" file* -lZ | xargs -0 rm#执行后会删除file1和file3，grep输出用-Z选项来指定以0值字节作为终结符文件名（\0），xargs -0 读取输入并用0值字节终结符分隔文件名，然后删除匹配文件，-Z通常和-l结合使用。 grep静默输出 123$ grep -q "test" filename#不会输出任何信息，如果命令运行成功返回0，失败则返回非0值。一般用于条件测试。 打印出匹配文本之前或者之后的行 1234567891011#显示匹配某个结果之后的3行，使用 -A 选项：$ seq 10 | grep "5" -A 3#显示匹配某个结果之前的3行，使用 -B 选项：$ seq 10 | grep "5" -B 3#显示匹配某个结果的前三行和后三行，使用 -C 选项：$ seq 10 | grep "5" -C 3#如果匹配结果有多个，会用“--”作为各匹配结果之间的分隔符：$ echo -e "a\nb\nc\na\nb\nc" | grep a -A 1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux设置全路径显示]]></title>
    <url>%2Flinux%2Flinux-config-setallpath%2F</url>
    <content type="text"><![CDATA[在Linux中，编辑vi /etc/bashrc文件，搜索PS1=&quot;[\u@\h \W]，将大写的W改为w 修改前： 修改后: 效果显示:]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DF命令]]></title>
    <url>%2Flinux%2Flinux-shell-df%2F</url>
    <content type="text"><![CDATA[简介df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 参数说明12345678910111213141516-a或--all：包含全部的文件系统；--block-size=&lt;区块大小&gt;：以指定的区块大小来显示区块数目；-h或--human-readable：以可读性较高的方式来显示信息；-H或--si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes；-i或--inodes：显示inode的信息；-k或--kilobytes：指定区块大小为1024字节；-l或--local：仅显示本地端的文件系统；-m或--megabytes：指定区块大小为1048576字节；--no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值；-P或--portability：使用POSIX的输出格式；--sync：在取得磁盘使用信息前，先执行sync指令；-t&lt;文件系统类型&gt;或--type=&lt;文件系统类型&gt;：仅显示指定文件系统类型的磁盘信息；-T或--print-type：显示文件系统的类型；-x&lt;文件系统类型&gt;或--exclude-type=&lt;文件系统类型&gt;：不要显示指定文件系统类型的磁盘信息；--help：显示帮助；--version：显示版本信息。 示例查看系统磁盘设备，默认是KB为单位1$ df 结果显示： 字段说明：Filesystem: 文件系统1K-blocks: 1K-块Used: 已用Available: 可用Use%: 已用%Mounted on: 挂载点 使用-h选项以KB以上的单位来显示，可读性高1$ df -h 结果显示：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>df</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Route命令]]></title>
    <url>%2Flinux%2Flinux-shell-route%2F</url>
    <content type="text"><![CDATA[简介route命令用来显示并设置Linux内核中的网络路由表，route命令设置的路由主要是静态路由。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。 在Linux系统中设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的ip地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。 参数说明1234567-A：设置地址类型；-C：打印将Linux核心的路由缓存；-v：详细信息模式；-n：不执行DNS反向查找，直接显示数字形式的IP地址；-e：netstat格式显示路由表；-net：到一个网络的路由表；-host：到一个主机的路由表。 示例显示当前路由1$ route -n 结果显示： 字段说明： U Up表示此路由当前为启动状态。H Host，表示此网关为一主机。G Gateway，表示此网关为一路由器。R Reinstate Route，使用动态路由重新初始化的路由。D Dynamically,此路由是动态性地写入。M Modified，此路由是由路由守护程序或导向器动态修改。! 表示此路由当前为关闭状态。 添加网关/设置网关1$ route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 屏蔽一条路由1$ route add -net 224.0.0.0 netmask 240.0.0.0 reject 删除路由记录12$ route del -net 224.0.0.0 netmask 240.0.0.0$ route del -net 224.0.0.0 netmask 240.0.0.0 reject 删除和添加设置默认网关12$ route del default gw 192.168.120.240$ route add default gw 192.168.120.240]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>route</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tail命令]]></title>
    <url>%2Flinux%2Flinux-shell-tail%2F</url>
    <content type="text"><![CDATA[简介tail命令用于输入文件中的尾部内容。tail命令默认在屏幕上显示指定文件的末尾10行。如果给定的文件不止一个，则在显示的每个文件前面加一个文件名标题。如果没有指定文件或者文件名为“-”，则读取标准输入。 注意：如果表示字节或行数的N值之前有一个”+”号，则从文件开头的第N项开始显示，而不是显示文件的最后N项。N值后面可以有后缀：b表示512，k表示1024，m表示1 048576(1M)。 参数说明1234567891011--retry：即是在tail命令启动时，文件不可访问或者文件稍后变得不可访问，都始终尝试打开文件。使用此选项时需要与选项“——follow=name”连用；-c&lt;N&gt;或——bytes=&lt;N&gt;：输出文件尾部的N（N为整数）个字节内容；-f&lt;name/descriptor&gt;或；--follow&lt;nameldescript&gt;：显示文件最新追加的内容。“name”表示以文件名的方式监视文件的变化。“-f”与“-fdescriptor”等效；-F：与选项“-follow=name”和“--retry"连用时功能相同；-n&lt;N&gt;或——line=&lt;N&gt;：输出文件的尾部N（N位数字）行内容。--pid=&lt;进程号&gt;：与“-f”选项连用，当指定的进程号的进程终止后，自动退出tail命令；-q或——quiet或——silent：当有多个文件参数时，不输出各个文件名；-s&lt;秒数&gt;或——sleep-interal=&lt;秒数&gt;：与“-f”选项连用，指定监视文件变化时间隔的秒数；-v或——verbose：当有多个文件参数时，总是输出各个文件名；--help：显示指令的帮助信息；--version：显示指令的版本信息。 示例显示文件末尾内容1$ tail -n 5 log2014.log 循环查看文件内容1$ tail -f test.log 从第5行开始显示文件1$ tail -n +5 log2014.log]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>tail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LN命令]]></title>
    <url>%2Flinux%2Flinux-shell-ln%2F</url>
    <content type="text"><![CDATA[简介ln命令用来为文件创件连接，连接类型分为硬连接和符号连接两种，默认的连接类型是硬连接。如果要创建符号连接必须使用-s选项。 注意：符号链接文件不是一个独立的文件，它的许多属性依赖于源文件，所以给符号链接文件设置存取权限是没有意义的。 参数说明1234567891011-b: 删除，覆盖以前建立的链接-d: 允许超级用户制作目录的硬链接-f: 强制执行-i: 交互模式，文件存在则提示用户是否覆盖-n: 把符号链接视为一般目录-s: 软链接(符号链接)-v: 显示详细的处理过程-S: “-S&lt;字尾备份字符串&gt; ”或 “--suffix=&lt;字尾备份字符串&gt;”-V: “-V&lt;备份方式&gt;”或“--version-control=&lt;备份方式&gt;”--help: 显示帮助信息--version: 显示版本信息 示例建立一个符号链接 在目录/usr/liu下建立一个符号链接文件abc，使它指向目录/usr/mengqc/mub1 1$ ln -s /usr/mengqc/mub1 /usr/liu/abc 删除一个符号链接 将目录/usr/liu/下的abc链接删除，注意不是rm -rf symbolic_name/ 12$ cd /usr/liu/$ rm -rf symbolic_name]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ln</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LS命令]]></title>
    <url>%2Flinux%2Flinux-shell-ls%2F</url>
    <content type="text"><![CDATA[简介ls命令用来显示目标列表，在Linux中是使用率较高的命令。ls命令的输出信息可以进行彩色加亮显示，以分区不同类型的文件。 参数说明12345678910111213141516171819202122-a：显示所有档案及目录（ls内定将档案名或目录名称为“.”的视为影藏，不会列出）；-A：显示除影藏文件“.”和“..”以外的所有文件列表；-C：多列显示输出结果。这是默认选项；-l：与“-C”选项功能相反，所有输出信息用单列格式输出，不输出为多列；-F：在每个输出项后追加文件的类型标识符，具体含义：“*”表示具有可执行权限的普通文件，“/”表示目录，“@”表示符号链接，“|”表示命令管道FIFO，“=”表示sockets套接字。当文件为普通文件时，不输出任何标识符；-b：将文件中的不可输出的字符以反斜线“”加字符编码的方式输出；-c：与“-lt”选项连用时，按照文件状态时间排序输出目录内容，排序的依据是文件的索引节点中的ctime字段。与“-l”选项连用时，则排序的一句是文件的状态改变时间；-d：仅显示目录名，而不显示目录下的内容列表。显示符号链接文件本身，而不显示其所指向的目录列表；-f：此参数的效果和同时指定“aU”参数相同，并关闭“lst”参数的效果；-i：显示文件索引节点号（inode）。一个索引节点代表一个文件；--file-type：与“-F”选项的功能相同，但是不显示“*”；-k：以KB（千字节）为单位显示文件大小；-l：以长格式显示目录下的内容列表。输出的信息从左到右依次包括文件名，文件类型、权限模式、硬连接数、所有者、组、文件大小和文件的最后修改时间等；-m：用“,”号区隔每个文件和目录的名称；-n：以用户识别码和群组识别码替代其名称；-r：以文件名反序排列并输出目录内容列表；-s：显示文件和目录的大小，以区块为单位；-t：用文件和目录的更改时间排序；-L：如果遇到性质为符号链接的文件或目录，直接列出该链接所指向的原始文件或目录；-R：递归处理，将指定目录下的所有文件及子目录一并处理；--full-time：列出完整的日期与时间；--color[=WHEN]：使用不同的颜色高亮显示不同类型的。 示例使用长清单模式1$ ls -l 显示文件大小1$ ls -lh 排序文件大小1$ ls -lhS 测量大小1$ ls -l --block-size=M 显示隐藏文件1$ ls -a 只列出目录条目1$ ls -d */ 不打印所有者信息1$ ls -g 不打印组信息1$ ls -lG 打印UID和GID1$ ls -n 不带颜色打印1$ ls --color=never 打印每个文件的索引号1$ ls -li 增加 / (斜线) 标记目录1$ ls -p 排序时反转顺序1$ ls -r 递归列出子目录1$ ls -R 扩展名排序1$ ls -lX 通过修改时间列出1$ ls -lt 列出你的主目录1$ ls ~ 打印ls命令版本1$ ls --version]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP响应头和请求头信息对照表]]></title>
    <url>%2Fhttp%2Fhttp-header%2F</url>
    <content type="text"><![CDATA[简介HTTP请求头提供了关于请求，响应或者其他的发送实体的信息。HTTP的头信息包括通用头、请求头、响应头和实体头四个部分。每个头域由一个域名，冒号（:）和域值三部分组成。 通用头标：即可用于请求，也可用于响应，是作为一个整体而不是特定资源与事务相关联。 请求头标：允许客户端传递关于自身的信息和希望的响应形式。 响应头标：服务器和于传递自身信息的响应。 实体头标：定义被传送资源的信息。即可用于请求，也可用于响应。 根据以上分类的HTTP请求头介绍可以参考此文，本工具根据请求和输出分为Request和Response两部分。 HTTP Request Header Header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/html Accept-Charset 浏览器可以接受的字符编码集。 Accept-Charset: iso-8859-5 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型。 Accept-Encoding: gzip, deflate Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接。（HTTP 1.1默认进行持久连接） Connection: keep-alive Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 Cookie: admckid=1607301350151121825; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 c.xxx.com.cn If-Match 只有请求内容与实体相匹配才有效 If-Match: “737060cd8c284d8af7ad3082f209582d” If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: “737060cd8c284d8af7ad3082f209582d” If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: “737060cd8c284d8af7ad3082f209582d” If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后,即来路 Referer: http://www.iqiyi.com/a_19rrhahmi9.html TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent 内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning HTTP Responses Header Header 解释 示例 Accept-Ranges 表明服务器是否支持指定范围请求及哪种类型的分段请求 Accept-Ranges: bytes Age 从原始服务器到代理缓存形成的估算时间（以秒计，非负） Age: 12 Allow 对某网络资源的有效的请求行为，不允许则返回405 Allow: GET, HEAD Cache-Control 告诉所有的缓存机制是否可以缓存及哪种类型 Cache-Control: max-age=31536000 Content-Encoding web服务器支持的返回内容压缩编码类型。 Content-Encoding: gzip Content-Language 响应体的语言 Content-Language: en,zh Content-Length 响应体的长度 Content-Length: 348 Content-Location 请求资源可替代的备用的另一地址 Content-Location: /index.htm Content-MD5 返回资源的MD5校验值 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 在整个返回体中本部分的字节位置 Content-Range: bytes 21010-47021/47022 Content-Type 返回内容的MIME类型 Content-Type: application/octet-stream Date 原始服务器消息发出的时间 Mon, 15 Aug 2016 02:43:15 GMT ETag 请求变量的实体标签的当前值 ETag: “737060cd8c284d8af7ad3082f209582d” Expires 响应过期的日期和时间 Expires: Tue, 15 Aug 2017 02:42:58 GMT Last-Modified 请求资源的最后修改时间 Last-Modified: Fri, 29 Jul 2016 16:26:41 GMT Location 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源 Location: http://www.xxx.com/act/RdFHgKt4WyNYv27z.html P3P P3P提供的个人隐私保护策略 P3P: CP=CURa ADMa DEVa PSAo PSDo OUR BUS UNI PUR INT DEM STA PRE COM NAV OTC NOI DSP COR Pragma 包括实现特定的指令，它可应用到响应链上的任何接收方 Pragma: no-cache Proxy-Authenticate 它指出认证方案和可应用到代理的该URL上的参数 Proxy-Authenticate: Basic refresh 应用于重定向或一个新的资源被创造，在5秒之后重定向（由网景提出，被大部分浏览器支持） Refresh: http://www.xxx.com/ Retry-After 如果实体暂时不可取，通知客户端在指定时间之后再次尝试 Retry-After: 120 Server web服务器软件名称 Server: nginx/7ed94dd662ffeb274371f6f0438ac6587fed8d84 Set-Cookie 设置Http Cookie Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1 Trailer 指出头域在分块传输编码的尾部存在 Trailer: Max-Forwards Transfer-Encoding 文件传输编码 Transfer-Encoding:chunked Vary 告诉下游代理是使用缓存响应还是从原始服务器请求 Vary: * Via 告知代理客户端响应是通过哪里发送的 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 警告实体可能存在的问题 Warning: 199 Miscellaneous warning WWW-Authenticate 表明客户端请求实体应该使用的授权方案 WWW-Authenticate: Basic]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIME类型列表]]></title>
    <url>%2Fhttp%2Fhttp-mime%2F</url>
    <content type="text"><![CDATA[简介MIME (Multipurpose Internet Mail Extensions) 是描述消息内容类型的因特网标准。MIME 消息能包含文本、图像、音频、视频以及其他应用程序专用的数据。官方的 MIME 信息是由 Internet Engineering Task Force (IETF) 在下面的文档中提供的： RFC-822 Standard for ARPA Internet text messagesRFC-2045 MIME Part 1: Format of Internet Message BodiesRFC-2046 MIME Part 2: Media TypesRFC-2047 MIME Part 3: Header Extensions for Non-ASCII TextRFC-2048 MIME Part 4: Registration ProceduresRFC-2049 MIME Part 5: Conformance Criteria and Examples 不同的应用程序支持不同的 MIME 类型。下面的参考手册是由 Microsoft Internet Information Server version 5 所支持的 MIME 类型列表。 按照内容类型排列的 Mime 类型列表 类型/子类型 扩展名 application/envoy evy application/fractals fif application/futuresplash spl application/hta hta application/internet-property-stream acx application/mac-binhex40 hqx application/msword doc application/msword dot application/octet-stream * application/octet-stream bin application/octet-stream class application/octet-stream dms application/octet-stream exe application/octet-stream lha application/octet-stream lzh application/oda oda application/olescript axs application/pdf pdf application/pics-rules prf application/pkcs10 p10 application/pkix-crl crl application/postscript ai application/postscript eps application/postscript ps application/rtf rtf application/set-payment-initiation setpay application/set-registration-initiation setreg application/vnd.ms-excel xla application/vnd.ms-excel xlc application/vnd.ms-excel xlm application/vnd.ms-excel xls application/vnd.ms-excel xlt application/vnd.ms-excel xlw application/vnd.ms-outlook msg application/vnd.ms-pkicertstore sst application/vnd.ms-pkiseccat cat application/vnd.ms-pkistl stl application/vnd.ms-powerpoint pot application/vnd.ms-powerpoint pps application/vnd.ms-powerpoint ppt application/vnd.ms-project mpp application/vnd.ms-works wcm application/vnd.ms-works wdb application/vnd.ms-works wks application/vnd.ms-works wps application/winhlp hlp application/x-bcpio bcpio application/x-cdf cdf application/x-compress z application/x-compressed tgz application/x-cpio cpio application/x-csh csh application/x-director dcr application/x-director dir application/x-director dxr application/x-dvi dvi application/x-gtar gtar application/x-gzip gz application/x-hdf hdf application/x-internet-signup ins application/x-internet-signup isp application/x-iphone iii application/x-javascript js application/x-latex latex application/x-msaccess mdb application/x-mscardfile crd application/x-msclip clp application/x-msdownload dll application/x-msmediaview m13 application/x-msmediaview m14 application/x-msmediaview mvb application/x-msmetafile wmf application/x-msmoney mny application/x-mspublisher pub application/x-msschedule scd application/x-msterminal trm application/x-mswrite wri application/x-netcdf cdf application/x-netcdf nc application/x-perfmon pma application/x-perfmon pmc application/x-perfmon pml application/x-perfmon pmr application/x-perfmon pmw application/x-pkcs12 p12 application/x-pkcs12 pfx application/x-pkcs7-certificates p7b application/x-pkcs7-certificates spc application/x-pkcs7-certreqresp p7r application/x-pkcs7-mime p7c application/x-pkcs7-mime p7m application/x-pkcs7-signature p7s application/x-sh sh application/x-shar shar application/x-shockwave-flash swf application/x-stuffit sit application/x-sv4cpio sv4cpio application/x-sv4crc sv4crc application/x-tar tar application/x-tcl tcl application/x-tex tex application/x-texinfo texi application/x-texinfo texinfo application/x-troff roff application/x-troff t application/x-troff tr application/x-troff-man man application/x-troff-me me application/x-troff-ms ms application/x-ustar ustar application/x-wais-source src application/x-x509-ca-cert cer application/x-x509-ca-cert crt application/x-x509-ca-cert der application/ynd.ms-pkipko pko application/zip zip audio/basic au audio/basic snd audio/mid mid audio/mid rmi audio/mpeg mp3 audio/x-aiff aif audio/x-aiff aifc audio/x-aiff aiff audio/x-mpegurl m3u audio/x-pn-realaudio ra audio/x-pn-realaudio ram audio/x-wav wav image/bmp bmp image/cis-cod cod image/gif gif image/ief ief image/jpeg jpe image/jpeg jpeg image/jpeg jpg image/pipeg jfif image/svg+xml svg image/tiff tif image/tiff tiff image/x-cmu-raster ras image/x-cmx cmx image/x-icon ico image/x-portable-anymap pnm image/x-portable-bitmap pbm image/x-portable-graymap pgm image/x-portable-pixmap ppm image/x-rgb rgb image/x-xbitmap xbm image/x-xpixmap xpm image/x-xwindowdump xwd message/rfc822 mht message/rfc822 mhtml message/rfc822 nws text/css css text/h323 323 text/html htm text/html html text/html stm text/iuls uls text/plain bas text/plain c text/plain h text/plain txt text/richtext rtx text/scriptlet sct text/tab-separated-values tsv text/webviewhtml htt text/x-component htc text/x-setext etx text/x-vcard vcf video/mpeg mp2 video/mpeg mpa video/mpeg mpe video/mpeg mpeg video/mpeg mpg video/mpeg mpv2 video/quicktime mov video/quicktime qt video/x-la-asf lsf video/x-la-asf lsx video/x-ms-asf asf video/x-ms-asf asr video/x-ms-asf asx video/x-msvideo avi video/x-sgi-movie movie x-world/x-vrml flr x-world/x-vrml vrml x-world/x-vrml wrl x-world/x-vrml wrz x-world/x-vrml xaf x-world/x-vrml xof]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PS命令]]></title>
    <url>%2Flinux%2Flinux-shell-ps%2F</url>
    <content type="text"><![CDATA[简介要对进程进行监测和控制,首先必须要了解当前进程的情况,也就是需要查看当前进程,而ps命令就是最基本同时也是非常强大的进程查看命令.使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵尸、哪些进程占用了过多的资源等等.总之大部分信息都是可以通过执行该命令得到的. 参数说明12345678-a：显示现行终端机下的所有进程，包括其他用户的进程-A：所有的进程均显示出来，与 -e 具有同样的效用-u：以用户为主的进程状态-f：做一个更为完整的输出-e：等于“-A”x： 通常与 a 这个参数一起使用，可列出较完整信息l： 较长、较详细的将该 PID 的的信息列出j： 工作的格式 (jobs format) PS L字段说明 F ：代表这个程序的旗标 (flag)， 4 代表使用者为 super userS ：代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍UID ：程序被该 UID 所拥有PID ：就是这个程序的 ID ！PPID ：则是其上级父程序的IDC ：CPU 使用的资源百分比PRI ：这个是 Priority (优先执行序) 的缩写，详细后面介绍NI ：这个是 Nice 值，在下一小节我们会持续介绍ADDR ：这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“SZ ：使用掉的内存大小WCHAN ：目前这个程序是否正在运作当中，若为 - 表示正在运作TTY ：登入者的终端机位置TIME ：使用掉的 CPU 时间。CMD ：所下达的指令为何 PS AUX字段说明 USER：该进程属于那个使用者账号的？PID ：该进程的进程ID号。%CPU：该进程使用掉的 CPU 资源百分比；%MEM：该进程所占用的物理内存百分比；VSZ ：该进程使用掉的虚拟内存量 (Kbytes)RSS ：该进程占用的固定的内存量 (Kbytes)TTY ：该进程是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。START：该进程被触发启动的时间；TIME ：该进程实际使用 CPU 运作的时间。COMMAND：该程序的实际指令为什么？ STAT：该程序目前的状态，主要的状态有： R ：该程序目前正在运作，或者是可被运作； S ：该程序目前正在睡眠当中 (可说是 idle 状态啦！)，但可被某些讯号(signal) 唤醒。 T ：该程序目前正在侦测或者是停止了； Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 示例显示所有进程信息1$ ps -A 显示指定用户信息1$ ps -u root 显示所有进程信息，连同命令行1$ ps -ef ps 与grep 常用组合用法，查找特定进程1$ ps -ef|grep ssh 列出类似程序树的程序显示1$ ps -axjf 找出与 cron 与 syslog 这两个服务有关的 PID 号码1$ ps aux | egrep '(cron|syslog)']]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WGET命令]]></title>
    <url>%2Flinux%2Flinux-shell-wget%2F</url>
    <content type="text"><![CDATA[简介wget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 参数说明12345678910111213141516171819202122-a&lt;日志文件&gt;：在指定的日志文件中记录资料的执行过程；-A&lt;后缀名&gt;：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；-b：进行后台的方式运行wget；-B&lt;连接地址&gt;：设置参考的连接地址的基地地址；-c：继续执行上次终端的任务；-C&lt;标志&gt;：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；-d：调试模式运行指令；-D&lt;域名列表&gt;：设置顺着的域名列表，域名之间用“，”分隔；-e&lt;指令&gt;：作为文件“.wgetrc”中的一部分执行指定的指令；-h：显示指令帮助信息；-i&lt;文件&gt;：从指定文件获取要下载的URL地址；-l&lt;目录列表&gt;：设置顺着的目录列表，多个目录用“，”分隔；-L：仅顺着关联的连接；-r：递归下载方式；-nc：文件存在时，下载文件不覆盖原有文件；-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；-q：不显示指令执行过程；-nh：不查询主机名称；-v：显示详细执行过程；-V：显示版本信息；--passive-ftp：使用被动模式PASV连接FTP服务器；--follow-ftp：从HTML文件中下载FTP连接文件。 示例下载单个文件 以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。 1$ wget http://www.xxx.net/xxx.zip 下载并以不同的文件名保存 wget默认会以最后一个符合/的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 1$ wget -O wordpress.zip http://www.xxx.net/xxx.aspx?id=1080 wget限速下载 当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。 1$ wget --limit-rate=300k http://www.xxx.net/testfile.zip 使用wget断点续传 使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。 1$ wget -c http://www.xxx.net/testfile.zip 使用wget后台下载1$ wget -b http://www.xxx.net/testfile.zip 伪装代理名称下载1$ wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" http://www.xxx.net/testfile.zip 测试下载链接 当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider参数进行检查。 1$ wget --spider URL 增加重试次数 如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。 1$ wget --tries=40 URL 下载多个文件 首先，保存一份下载链接文件：cat &gt; filelist.txturl1url2url3url4接着使用这个文件和参数-i下载。 1$ wget -i filelist.txt 镜像网站 下载整个网站到本地。–miror开户镜像下载。-p下载所有为了html页面显示正常的文件。–convert-links下载后，转换成本地的链接。-P ./LOCAL保存所有文件和目录到本地指定目录。 1$ wget --mirror -p --convert-links -P ./LOCAL URL 过滤指定格式下载 下载一个网站，但你不希望下载图片，可以使用这条命令。 1$ wget --reject=gif ur 把下载信息存入日志文件 不希望下载信息直接显示在终端而是在一个日志文件，可以使用。 1$ wget -o download.log URL 限制总下载文件大小 当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。 1$ wget -Q5m -i filelist.txt 下载指定格式文件 可以在以下情况使用该功能：下载一个网站的所有图片。下载一个网站的所有视频。下载一个网站的所有PDF文件。 1$ wget -r -A.pdf url FTP下载12$ wget ftp-url$ wget --ftp-user=USERNAME --ftp-password=PASSWORD url Https下载1$ wget -r -np -nd --accept=gz --no-check-certificate https://www.xxx.com/dir/ --http-user=username --http-password=password]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>wget</tag>
      </tags>
  </entry>
</search>
